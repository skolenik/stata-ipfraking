\inserttype[st0001]{article}
\author{S. Kolenikov}{%
  Stanislav Kolenikov\\Abt Associates\\stas\_kolenikovs@abtassoc.com
}
\title[Raking survey data: updates]{Updates to the ipfraking ecosystem}
\maketitle

\begin{abstract}
\citet{kolenikov:2014} introduced package \stcmd{ipfraking}
for weight calibration procedures known as iterative proportional fitting,
or raking, of complex survey weights.
This article briefly describes the original package,
and adds updates to the core program, as well as a host of
additional programs that are used to support the process of creating
survey weights in the authors' production code.

\keywords{\inserttag, survey, calibration, weights, raking}
\end{abstract}

\section{Introduction and background}

Large scale social, behavioral and health data are often collected
via complex survey designs that may involve some or all of stratification,
multiple stages of selection and unequal probabilities of selection
\citep{korn:graubard:1995,korn:graubard:1999}.
In an ideal setting, varying probabilities of selection are
accounted for by using the Horvitz-Thompson estimator of the totals
\citep{horvitz:thompson:1952,thompson:1997}, and the remaining
sampling fluctuations can be further ironed out by
post-stratification \citep{holt:smith:1979}.
However, on top of the planned differences in probabilities of obtaining
a response from a sampled unit, non-response is a practical problem
that has been growing more acute over the recent years
\citep{groves:dillman:eltinge:little:2001,pew:2012}.
The analysis weights that are provided along with the public use
microdata by data collecting agencies are designed to account
for unequal probabilities of selection, non-response, and other factors
affecting imbalance between the population and the sample, thus making
the analyses conducted on such microdata generalizable to the target population.

Earlier, I introduced \citep{kolenikov:2014} a Stata package
called \stcmd{ipfraking} that implements
calibration of survey weights to known control totals to ensure
that the resulting weighted data are representative of the population
of interest. The process of calibration is aimed at aligning the sample totals
of the key variables with those known for the population as a whole.
The remainder of this section provides a condensed treatment of estimation
with survey data using calibrated weights; full treatment was provided
in the original paper.

For a given finite population $\mathcal U$ of units indexed $i=1,\ldots,N$,
the interests of survey statisticians often lie in estimating the
population total of a variable $Y$
\begin{equation}
   T[Y] = \sum_{i \in \mathcal{U}} Y_i
   \label{eq:total:pop}
\end{equation}
A sample $\mathcal S$ of $n$ units indexed by $j=1,\ldots,n$
is taken from $\mathcal U$. If the probability to select the
$i$-th unit is known to be $\pi_i$, then
the {\it probability weights}, or {\it design weights}, are given by
the inverse probability of selection:
\begin{equation}
   w_{1i} = \pi_i^{-1}
   \label{eq:prob:weight}
\end{equation}
With these weights, an unbiased
(design-based, non-parametric) estimator
of the total (\ref{eq:total:pop}) is \citep{horvitz:thompson:1952}
\begin{equation}
   t_{1}[y] = \sum_{j \in \mathcal{S}} \frac{y_j}{\pi_j}
   \equiv \sum_{j \in \mathcal{S}} w_{1j} y_j
   \label{eq:total:sample},
\end{equation}
The subindex $1$ indicates that the weights $w_{1i}$ were
used in obtaining this estimator. Probability weights protect
the end user from potentially informative sampling designs, in which
the probabilities of selection are correlated with outcomes, and
the design-based methods generally ensure that inference can be generalized
to the finite population even when the statistical models used
by analysts and researchers are not specified correctly
\citep{pfeff:1993,binder:roberts:2003}.

Often, survey statisticians have auxiliary information on the units
in the frame, and such information can be included it at the sampling stage
to create more efficient designs. Unequal probabilities of selection
are then controlled with probability weights, implemented
as \stcmd{[pw=}{\it exp}\stcmd{]} in Stata (and can be permanently
affixed to the data set with \stcmd{svyset} command).

In many situations, however, usable information is not available beforehand,
and may only appear in the collected data. The census totals of the age and gender
distribution of the population may exist, but age and gender of
the sampled units is unknown until the survey measurement is taken on them.
It is still possible to capitalize on this additional data by
adjusting the weights in such a way that the reweighted data
conforms to these known figures. The procedures to perform these
reweighting steps are generally known as {\it weight calibration}
\citep{deville:sarndal:1992,deville:sarndal:sautory:1993,%
kott:2006,kott:2009,sarndal:2007}.

Suppose there are several (categorical) variables, referred to
as {\it control variables}, that are available for both
the population and the sample
(age groups, race, gender, educational attainment, etc.).
Weight calibration aims at adjusting the margins, or low level interactions,
via an iterative optimization aimed at satisfying
the {\it control totals} for the control variables $\mathbf{x}=(x_1, \ldots, x_p)$:
\begin{equation}
    \sum_{j \in \mathcal{S}} w_{3j} \mathbf{x}_j
    = T [ \mathbf{X}_j  ]
    \label{eq:control:totals}
\end{equation}
where the right hand side is assumed to be known from a census or
a higher quality survey.
\citet{deville:sarndal:1992} framed the problem of finding a suitable
set of weights as that of constrained optimization with the control
equations (\ref{eq:control:totals}) serving as constraints,
and optimization targeted at making the discrepancy between
the design weights $w_{1j}$ and calibrated weights
$w_{3j}$ as close as possible, in a suitable sense.

In package \stcmd{ipfraking} \citep{kolenikov:2014}, I implemented
a popular calibration algorithm, known as \textit{iterated proportional fitting},
or as \textit{raking}, which consists of iterative updating (post-stratification) of
each of the margins. (For an in-depth discussion of distinctions between
raking and post-stratification, see \citet{kolenikov:2016}.)
Since 2014, the continuing code development resulted
in additional features that this update documents.

\section{Updates to \stcmd{ipfraking} program and package}

Below, I provide full syntax, and list the new features in a dedicated section.

\subsection{Syntax of \stcmd{ipfraking}}
\label{subsec:syntax}

\begin{stsyntax}
ipfraking
\optif\
\optin\
\optweight\
,
\underbar{ctot}al({\it matname} [{\it matname \ldots}])
\optional{
\underbar{gen}erate(\newvarname)
replace
double
\underbar{iter}ate(\num)
\underbar{tol}erance(\num)
\underbar{ctrltol}erance(\num)
trace
\underbar{nodiv}ergence
trimhiabs(\num)
trimhirel(\num)
trimloabs(\num)
trimlorel(\num)
trimfrequency(once|sometimes|often)
double
meta
nograph
}
\end{stsyntax}

\hangpara
Note that the weight statement \stcmd{[pw=\varname]} is required, and must contain the initial weights.

\subsubsection{Required options}

\hangpara
\stcmd{\underbar{ctot}al(}{\it matname} \LB{\it matname \ldots}\RB\stcmd{)}
supplies the names of the matrices that contain the control
totals, as well as meta-data about the variables to be used
in calibration.

\begin{sttech}
The row and column names of the control total matrices
(see \pref{matrix rownames}) should be formatted as follows.
\begin{itemize}
    \item \stcmd{rownames}: the name of the control variable
    \item \stcmd{colnames}: the values the control variables takes
    \item \stcmd{coleq}: the name of the variable for which total is computed;
          typically it is identically equal to 1.
\end{itemize}
See examples in Section \ref{sec:examples}.
\end{sttech}

\hangpara
\stcmd{\underbar{gen}erate(\newvarname)}
contains the name of the new variable to contain the raked weights.

\hangpara
\stcmd{replace} indicates that the weight variable supplied in the
\stcmd{[pw=\varname]} expression should be overwritten with the new weights.

One and only one of \stcmd{generate()} or \stcmd{replace} must be specified.

\subsubsection{Linear calibration}

\hangpara
\stcmd{\underbar{lin}ear}
requests linear calibration of weights.

\subsubsection{Options to control convergence}

\hangpara
\stcmd{\underbar{tol}erance(\num)} defines convergence criteria
(the change of weights from one iteration to next). The default is $10^{-6}$.

\hangpara
\stcmd{\underbar{iter}ate(\num)} specifies the maximum number
of iterations. The default is 2000.

\hangpara
\stcmd{\underbar{nodiv}ergence} overrides the check
that the change in weights is greater at the current iteration
than in the previous one, i.e., ignores this termination condition.
It is generally recommended, especially in calibration with simultaneous trimming.

\hangpara
\stcmd{\underbar{ctrltol}erance(\num)} defines the criterion to
assess the accuracy of the control totals. It does not impact
iterations or convergence criteria, but rather only triggers alerts in the output.
The default value is $10^{-6}$.

\hangpara
\stcmd{trace} requests a trace plot to be added.

\subsubsection{Trimming options}
\label{subsubsec:trimming}

\hangpara
\stcmd{trimhiabs(\num)} specifies the upper bound $U$ on the greatest
    value of the raked weights.  The weights that
    exceed this value will be trimmed down, so that
    $w_{3j} \le U$ for every $j\in\mathcal{S}$.

\hangpara
\stcmd{trimhirel(\num)} specifies the upper bound $u$ on the adjustment
    factor over the baseline weight. The weights
    that exceed the baseline times this value will be trimmed down,
    so that $w_{3j} \le u w_{1j}$ for every $j\in\mathcal{S}$.

\hangpara
\stcmd{trimloabs(\num)} specifies the lower bound $L$ on the smallest value
    of the raked weights.  The weights that are smaller than this value will
    be increased, so that $w_{3j} \ge L$ for every $j\in\mathcal{S}$.

\hangpara
\stcmd{trimlorel(\num)} specifies the lower bound $l$ on the adjustment factor
    over the baseline weight.  The weights that are smaller than the baseline
    times this value will be increased, so that
    $w_{3j} \ge l w_{1j}$ for every $j\in\mathcal{S}$.

\hangpara
\stcmd{trimfreqency({\it keyword})} specifies when the trimming operations
    are to be performed. The following keywords are recognized:

\morehang \stcmd{often} means that trimming will be performed
    after each marginal adjustment.

\morehang \stcmd{sometimes} means that trimming will be performed
    after a full set of variables has been used for post-stratification.
    This is the default behavior if any of the numeric trimming
    options above are specified.

\morehang \stcmd{once}
    means that trimming will be performed after the raking process
    is declared to have converged.

The numeric trimming options \stcmd{trimhiabs(\num)}, \stcmd{trimhirel(\num)},
\stcmd{trimloabs(\num)}, \stcmd{trimlorel(\num)} can be specified in any combination,
or entirely omitted to produce untrimmed weights. By default, there is no trimming.

\subsubsection{Miscellaneous options}

\hangpara
\stcmd{double} specifies that the new variable named in \stcmd{generate()}
option should be generated as double type. See \dref{data types}.

\hangpara
\stcmd{meta} puts information taken by \stcmd{ipfraking} as inputs and produced
    throughout the process into characteristics stored with the variable specified in
    \stcmd{generate()} option. See Section \ref{subsec:example:meta}.

\hangpara
\stcmd{nograph} omits the histogram of the calibrated weights, which can be
used to speed up \stcmd{ipfraking} (e.g., in replicate weight production).

\subsection{New features of \stcmd{ipfraking}}

Since the first publication, the following features and options were added.

Reporting of results and errors by \stcmd{ipfraking} was improved in several directions.
\begin{enumerate}
    \item The discrepancy for the worst fitting category is now being reported.
    \item The number of trimmed observations is reported.
    \item If \stcmd{ipfraking} determines that the categories do not match
        in the control totals received from \stcmd{ctotals()} and those found in
        the data, a full listing of categories is provided, and the categories
        not found in one or the other are explicitly shown.
\end{enumerate}

Linear calibration (Case 1 of \citet{deville:sarndal:1992}) is provided with
\stcmd{linear} option. The weights are calculated analytically:
\begin{equation}
    \label{eq:linear:weight}
    w_{j,\rm{lin}} = w_{1j} (1+\mathbf{x}_j'\mathbf{\lambda}).
    \quad
    \mathbf{\lambda} = \Bigl( \sum_{j \in \mathcal{S}} w_{1j} \mathbf{x}_j \mathbf{x}_j' \Bigr)^{-1}
        ( T [ \mathbf{X}_j  ] - t_{1}[y] )
\end{equation}
This works very fast, but has an undesirable artefact of producing negative weights,
as the range of weights is not controlled. (As raking works by multiplying the currents
weights by positive factors, if the input weights are all positive, the output weights
will be positive as well.) Negative weights are not allowed by the official \stcmd{svy} commands
or commands that work with \stcmd{[pweights]}.
In author's experience, running linear weights first,
pulling up the negative and small positive weights (\stcmd{replace weight = 1 if weight <= 1})
and re-raking using the ``proper'' iterative proportional fitting runs faster than
raking from scratch. An example of linearly calibrated weights is given below
in Section \ref{subsec:linear}.

Option \stcmd{meta} saves more information in characteristics of the calibrated
weight variables.

\begin{stlog}
\input{ipfr.example5.log.tex}\nullskip
\end{stlog}

The following characteristics are stored with the newly created weight variable
(see \pref{char}).

\begin{tabular}{ll}
    \stcmd{command} & The full command as typed by the user \\
    {\it matrix name} & The relative matrix difference from the corresponding \\
                    & control total, see \dref{functions} \\
    \stcmd{trimhiabs}, \stcmd{trimloabs}, & Corresponding trimming options,
                    if specified \\
    \stcmd{trimhirel}, \stcmd{trimlorel}, & \\
    \stcmd{trimfrequency} & \\
    \stcmd{maxctrl} & the greatest \stcmd{mreldif} between the targets and the achieved \\
                    & weighted totals \\
    \stcmd{objfcn}  & the value of the relative weight change at exit \\
    \stcmd{converged} & whether \stcmd{ipfraking} exited due to convergence (1) \\
                    & vs. due to an increase in the objective function \\
                    & or reaching the limit on the number of iterations (0) \\\
    \stcmd{source}  & weight variable specified as the \stcmd{[pw=]} input \\
    \stcmd{worstvar}& the variable in which the greatest discrepancy between \\
                    & the targets and the achieved weighted totals \\
                    & (\stcmd{maxctrl}) was observed \\
    \stcmd{worstcat}& the category of the \stcmd{worstvar} variable in which the  \\
                    & greatest discrepancy was observed
\end{tabular}

For the control total matrices \num$=1,2,\ldots$, the following
meta-information is stored.

\begin{tabular}{ll}
    \stcmd{mat\num} & the name of the control total matrix \\
    \stcmd{totalof\num}& the multiplier variable (matrix' \stcmd{coleq} \\
    \stcmd{over\num}& the margin associated with the matrix \\
                    & (i.e., the categories represented by the columns)
\end{tabular}

Also, \stcmd{ipfraking} stores the notes regarding the control matrices
used, and which of the margins did not match the control totals, if any.
See \dref{notes}.

\subsection{Utility programs}
\label{subsec:utility}

The original package \stcmd{ipfraking} provided two additional utility programs,
\stcmd{mat2do} and \stcmd{xls2row}. An additional utility program was added
to compute the design effects and margins of error, common tasks associated
with describing survey weights. Specifically, the Transparency Initiative
of the American Association for Public Opinion Research
\citep{aapor:2014:ti:terms}
requires that

\begin{quote}
For probability samples, the estimates of sampling error will be reported, and the discussion will state whether or not the reported margins of sampling error or statistical analyses have been adjusted for the design effect due to weighting, clustering, or other factors.
\end{quote}

\begin{stsyntax}
whatsdeff
{\it weight\_variable}
\optif\
\optin\
,
\optional{
by(\varlist)
}
\end{stsyntax}

The utility program \stcmd{whatsdeff} calculates the apparent design effect due to unequal weighting,
${\rm DEFF_{UWE}}=1 + {CV}^2_w = $ \stcmd{1 + r(Var)/(r(mean))\^2} from \stcmd{summarize} {\it weight\_variable}.
Additionally, it reports the effective sample size, $n/{\rm DEFF_{UWE}}$, and also returns
the margins of error for the sample proportions that estimate the population proportions of
10\% and 50\%.

\begin{stlog}
\input{ipfr.whatsdeff.log.tex}\nullskip
\end{stlog}

\subsection{New programs in the package}

Two new programs are added to the package: \stcmd{ipfraking\_report} and \stcmd{wgtcellcollapse},
and are documented in the subsequent sections of this article. The former provides reports on the raked weights,
including summaries of the unweighted data, data with the input weights, and data with the raked weights. 
The latter creates a mostly automated flow of collapsing weighting cells that are too detailed
(and hence have low sample sizes).

\section{Excel reports on raked weights:  \stcmd{ipfraking\_report}}

\begin{stsyntax}
ipfraking\_report
using \textit{filename}
,
raked\_weight(\varname)
\optional{
matrices(\textit{namelist})
by(\varlist)
xls
replace
force
}
\end{stsyntax}

The utility command \stcmd{ipfraking\_report} produces a detailed report
describing the raked weights, and places it into \textit{filename}\stcmd{.dta} file
(or, if \stcmd{xls} option is specified, both \textit{filename}\stcmd{.dta} and \textit{filename}\stcmd{.xls}
files).

Along the way, \stcmd{ipfraking\_report} runs a regression of the log raking ratio $w_{3j}/w_{1j}$
on the calibration variables. This regression is expected to have $R^2$ very close to 1,
and the regression coefficients provide insights regarding which categories received
greater vs. smaller adjustments.

\cnp

\begin{stlog}
\input{ipfr.report1.log.tex}\nullskip
\end{stlog}

It looks like \stcmd{ipfraking} had to work harder to adjust the weights of older females,
and especially other race individuals.

\subsection{Options of \stcmd{ipfraking\_report}}

\hangpara
\stcmd{raked\_weight(\varname)} specifies the name of the raked weight variable to create
    the report for. This is a required option.

\hangpara
\stcmd{matrices(\textit{namelist})} specifies a list of matrices (formatted as the matrices
    supplied to \stcmd{ctotal()} option of \stcmd{ipfraking}) to produce weighting reports for.
    In particular, the variables and their categories are picked up from these matrices;
    and the control totals/proportions are compared to those defined by the weight being reported on.

\hangpara
\stcmd{by(\varlist)} specifies a list of additional variables for which the weights are to
    be tabulated in the raking weights report. The difference with the \stcmd{matrices()} option
    is that the control totals for these variables may not be known (or may not be relevant).
    In particular, \stcmd{by(\_one)}, where \stcmd{\_one} is identically one, will produce
    the overall report.

\hangpara
\stcmd{xls} requests exporting the report to an Excel file.

\hangpara
\stcmd{replace} specifies that the files produced by \stcmd{ipfraking\_report} (i.e., the \stcmd{.dta}
    and the {\stmcd{.xls}} file if \stcmd{xls} option is specified) should be overwritten.

\hangpara
\stcmd{force} requires that a variable that may be found repeatedly (between the calibration variables
    supplied originally to \stcmd{ipfraking}, the variables found in the independent total \stcmd{matrices()},
    and the variables without the control totals provided in \stcmd{by()} option) is processed every
    time it is encountered. (Otherwise, it is only processed once.)

\subsection{Variables in the raking report}

The raking report file contains the following variables.

\noindent
\begin{tabular}{ll}
  \hline
  Variable name & Definition \\
  \hline
  \stcmd{Weight\_Variable} & The name of the weight variable, \stcmd{generate()} \\
  \stcmd{C\_Total\_Margin\_Variable\_Name} & The name of the control margin, \\
            & \stcmd{rowname} of the corresponding \stcmd{ctotal()} matrix \\
  \stcmd{C\_Total\_Margin\_Variable\_Label} & The label of the control margin variable \\
  \stcmd{Variable\_Class} & The role of the variable in the report: \\
        & Raking margin: a variable used as a calibration margin \\
        & (picked up automatically from the \stcmd{ctotal()} \\
        & matrix, provided \stcmd{meta} option was specified) \\
        & Other known target: supplied with \stcmd{matrices()} \\
        & option of \stcmd{ipfraking\_report} \\
        & Auxiliary variable: additional variable supplied \\
        & with \stcmd{by()} option of \stcmd{ipfraking\_report} \\
  \stcmd{C\_Total\_Arg\_Variable\_Name} & The name of the multiplier variable \\
  \stcmd{C\_Total\_Arg\_Variable\_Label} & The label of the multiplier variable \\
  \stcmd{C\_Total\_Margin\_Category\_Number} & Numeric value of the control total category \\
  \stcmd{C\_Total\_Margin\_Category\_Label} &  Label of the control total category \\
  \stcmd{Category\_Total\_Target} & The control total to be calibrated to \\
        & (the specific entry in the \stcmd{ctotal()} matrix) \\
  \stcmd{Category\_Total\_Prop} & Control total proportion \\
        & (the ratio of the specific entry in the \stcmd{ctotal()} \\
        & matrix to the matrix total) \\
  \stcmd{Unweighted\_Count} & Number of sample observations in the category \\
  \stcmd{Unweighted\_Prop} & Unweighted proportion \\
  \stcmd{Unweighted\_Prop\_Discrep} & Difference \stcmd{Unweighted\_Prop} - \stcmd{Category\_Total\_Prop} \\
  \stcmd{Category\_Total\_SRCWGT} & Weighted category total, with source weight \\
  \stcmd{Category\_Prop\_SRCWGT} & Weighted category proportion, with source weight \\
  \stcmd{Category\_Total\_Discrep\_SRCWGT} & Difference \stcmd{Category\_Total\_SRCWGT} - \\
        & - \stcmd{Category\_Total\_Target} \\
  \stcmd{Category\_Prop\_Discrep\_SRCWGT} & Difference \stcmd{Category\_Prop\_SRCWGT} - \\
        & - \stcmd{Category\_Total\_Prop} \\
  \stcmd{Category\_RelDiff\_SRCWGT} & \stcmd{reldif(Category\_Total\_SRCWGT,} \\
        & \stcmd{Category\_Total\_Target)} \\
  \stcmd{Overall\_Total\_SRCWGT} & Sum of source weights \\
  \stcmd{Source} & The name of the matrix from which the totals \\
        & were obtained \\
  \stcmd{Comment} & Placeholder for comments, to be entered during \\
        & manual review \\
  \hline
\end{tabular}

For each of the input weights (\stcmd{SRCWGT} suffix), raked weights (\stcmd{RKDWGT} suffix) and raking ratio
(the ratio of raked and input weights, \stcmd{RKDRATIO} suffix), the following summaries are provided.

\begin{tabular}{ll}
  \hline
  Variable name & Definition \\
  \hline
  \stcmd{Min\_\textit{WEIGHT}} & Min of source weights \\
  \stcmd{P25\_\textit{WEIGHT}} & 25th percentile of source weights \\
  \stcmd{P50\_\textit{WEIGHT}} & Median of source weights \\
  \stcmd{P75\_\textit{WEIGHT}} & 75th percentile of source weights \\
  \stcmd{Max\_\textit{WEIGHT}} & Max of source weights \\
  \stcmd{Mean\_\textit{WEIGHT}} & Mean of source weights \\
  \stcmd{SD\_\textit{WEIGHT}} & Standard deviation of source weights \\
  \stcmd{DEFF\_\textit{WEIGHT}} & Apparent UWE DEFF of source weights \\
  \hline
\end{tabular}

\subsection{Example}

\begin{stlog}
\input{ipfr.report2.log.tex}\nullskip
\end{stlog}

Functionality of \stcmd{ipfraking\_report} is aimed at manual quality control review,
which typically involves (i) categories with raking factors that differ the most (in the output),
and (ii) the resulting report file in Excel,
although for some aspects of automated quality control, it can be useful, as well.

\section{Collapsing weighting cells:  \stcmd{wgtcellcollapse}}

An additional new component of \stcmd{ipfraking} package is a tool to
semi-automatically collapse weighting cells, in order to achieve
a required minimal size of the weighting cell. (A typical recommendation
is to have cells of size 30 to 50.)

\begin{stsyntax}
wgtcellcollapse \textit{task}
\optif\
\optin\
,
\optional{task\_options}
}
\end{stsyntax}

where \textit{task} is one of:

\hangpara
\stcmd{define} to define collapsing rules explicitly

\hangpara
\stcmd{sequence} to create collapsing rules for a sequence of categories

\hangpara
\stcmd{report} to list the currently defined collapsing rules

\hangpara
\stcmd{candidate} to find rules applicable to a given category

\hangpara
\stcmd{collapse} to perform cell collapsing

\hangpara
\stcmd{label} to label collapsed cells using the original labels after \stcmd{wgtcellcollapse collapse}

\subsection{Syntax of \stcmd{wgtcellcollapse report}}

\begin{stsyntax}
wgtcellcollapse report
,
\underbar{var}iables(\varlist)
\optional{
break
}
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iables(\varlist)} is the list of variables for which the collapsing rule are to be reported

\hangpara
\stcmd{break} requires \stcmd{wgtcellcollapse report} to exit with error when technical inconsistencies are encountered

\subsection{Syntax of \stcmd{wgtcellcollapse define}}

\begin{stsyntax}
wgtcellcollapse define
,
\underbar{var}iables(\varlist)
\optional{
from(\textit{numlist})
to(\num)
label(\ststring)
max(\num)
clear
}
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iables(\varlist)} is the list of variables for which the collapsing rule can be used

\hangpara
\stcmd{from(\textit{numlist})} is the list of categories that can be collapsed according to this rule

\hangpara
\stcmd{to(\num)} is the numeric value of the new, collapsed category

\hangpara
\stcmd{label(\ststring)} is the value label to be attached to the new, collapsed category

\hangpara
\stcmd{max(\num)} overrides the automatically determined max value of the collapsed variable

\hangpara
\stcmd{clear} clears all the rules currently defined

Individual collapsing rules can be defined as follows.

\begin{stlog}
\input{ipfr.collapse1.log.tex}\nullskip
\end{stlog}

Note how \stcmd{break} option of \stcmd{wgtcellcollapse} can be used to abort the execution
when technical deficiencies in the rules or in the data are encountered. In this case,
the label of the new category 123 was not defined, and this is considered a serious
enough deficiency to stop.

\begin{stlog}
\input{ipfr.collapse2.log.tex}\nullskip
\end{stlog}

\subsection{Syntax of \stcmd{wgtcellcollapse sequence}}


\begin{stsyntax}
wgtcellcollapse sequence
,
\underbar{var}iables(\varlist)
from(\textit{numlist})
depth(\num)
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iables(\varlist)} is the list of variables for which the collapsing rule can be used

\hangpara
\stcmd{from(\textit{numlist})} is the sequence of values from which the plausible subsequences can be constructed

\hangpara
\stcmd{depth(\num)} is the maximum number of the original categories that can be collapsed

Moderate length sequences of collapsing categories can be defined as follows.

\begin{stlog}
\input{ipfr.collapse3.log.tex}\nullskip
\end{stlog}

Note how \stcmd{wgtcellcollapse sequence} automatically created labels for the collapsed cells.

When creating sequential collapses, \stcmd{wgtcellcollapse sequence} uses the following mnemonics
in creating the new categories:
\begin{itemize}
    \item First comes the length of the collapsed subsequence (up to \stcmd{depth(\num)}).
    \item Then comes the starting value of the category in the subsequence (padded by zeroes as needed).
    \item Then comes the ending value of the category in the subsequence (padded by zeroes as needed).
\end{itemize}

In the example above, rules 7 through 9 lead to collapsing into the new category 324. This
should be interpreted as ``the subsequence of length 3 that starts with category 2 and ends with category 4''.
A numeric value of the collapsed category that reads like 50412 means
``the subsequence of length 5 that starts with category 4 and ends with category 12''.
In that second example, \stcmd{wgtcellcollapse sequence} padded the value of 4 with an additional zero,
so that the length of resulting collapsed category value is always (\stnum of digits of the sequence length) +
twice (\stnum of digits of the largest original category).

Note that \stcmd{wgtcellcollapse sequence} respects the order in which the categories are
supplied in the \stcmd{from()} option, and does not sort them. If the categories are supplied 
in the order 2, 4, 1 and 3, then \stcmd{wgtcellcollapse sequence} would collapse 2 with 4, 4 with 1, 
and 1 with 3:

\begin{stlog}
\input{ipfr.collapse5.log.tex}\nullskip
\end{stlog}


\subsection{Syntax of \stcmd{wgtcellcollapse candidate}}

\begin{stsyntax}
wgtcellcollapse candidate
,
\underbar{var}iable(\varname)
category(\num)
\optional{ \max{\num} }
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iable(\varname)} is the variable whose collapsing rules are to be searched

\hangpara
\stcmd{category(\num)} is the category for which the candidate rules are to be identified

\hangpara
\stcmd{max(\num)} is the maximum value of the categories in the candidate rules to be returned

The rules found are quietly returned through the mechanism of \stcmd{sreturn},
see \pref{return}, as they are intended to stay in memory sufficiently long for
\stcmd{wgtcellcollapse collapse} to evaluate each rule. Going back to the example
with sequential collapses of depth 3, we can identify the following candidates
for categories 2, 212 (collapsed values of 1 and 2), and a non-existent category of 55:

\begin{stlog}
\input{ipfr.collapse4.log.tex}\nullskip
\end{stlog}

In the second call to
the option \stcmd{max(9)} was used to restrict the returned rules to the rules
that deal with the original categories only (so rule 8 that involved a collapsed category 234 
was omitted). In the third call, a list of rules
that involve a collapsed category \stcmd{cat(212)} was requested. Requests
for nonexisting categories are not considered errors, but simply produce empty lists
of ``good rules''

\subsection{Syntax of \stcmd{wgtcellcollapse label}}

\begin{stsyntax}
wgtcellcollapse label
,
\underbar{var}iable(\varname)
\optional{ verbose force }
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iable(\varname)} is the collapsed variable to be labeled.

\hangpara
\stcmd{verbose} outputs the labeling results. There may be a lot of output.

\hangpara
\stcmd{force} instructs \stcmd{wgtcellcollapse label} to only use categories present in the data.

Example is given in section \ref{subsec:wgtcellcollapse:labels} below.

\subsection{Syntax of \stcmd{wgtcellcollapse collapse}}

\begin{stsyntax}
wgtcellcollapse collapse \optif \optin
,
\underbar{var}iables(\varlist)
mincellsize(\num)
\underbar{sav}ing(\textit{dofile\_name})
\optional{
\underbar{gen}erate(\newvarname)
replace
append
feed(\varname)
strict
sort(\varlist)
run
maxpass(\num)
\underbar{maxcat}egory(\num)
\underbar{zer}oes(\textit{numlist})
greedy
}
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iables(\varlist)} provides the list of variables whose cells are to be collapsed.
When more than one variable is specified, \stcmd{wgtcellcollapse collapse} proceeds from right to left,
i.e., first attempts to collapse the rightmost variable.

\hangpara
\stcmd{mincellsize(\num)} specifies the minimum cell size for the collapsed cells. For most weighting
purposes, values of 30 to 50 can be recommended.

\hangpara
\stcmd{\underbar{gen}erate(\newvarname)} specifies the name of the collapsed variable to be created.

\hangpara
\stcmd{feed(\varname)} provides the name of an already existing collapsed variable.

\hangpara
\stcmd{strict} modifies the behavior of \stcmd{wgtcellcollapse collapse} so that only
collapsing rules for which all participating categories have nonzero counts are utilized.

\hangpara
\stcmd{sort(\varlist)} sorts the data set before proceeding to collapse the cell.
The default sort order is in terms of the values of the collapsed variable.
A different sort order may produce a different set of collapsed cell when
cells are tied on size.

\hangpara
\stcmd{maxpass(\num)} specifies the maximum number of passes through the data set. The default value is 10000.}

\hangpara
\stcmd{\underbar{maxcat}egory(\num)} is the maximum category value of the variable being collapsed.
It is passed to the internal calls to \stcmd{wgtcellcollapse candidate}, see above.

\hangpara
\stcmd{\underbar{zer}oes(\textit{numlist})} provides a list of the categories of the collapsed
variable that may have zero counts in the data.

\hangpara
\stcmd{greedy} modifies the behavior \stcmd{wgtcellcollapse collapse} to prefer the rules
that collapse the maximum number of categories.

Options to deal with the do-file to write the collapsing code to:	

\hangpara
\stcmd{\underbar{sav}ing(\textit{dofile\_name})} specifies the name of the do-file that will contain the cell collapsing code.

\hangpara
\stcmd{replace} overwrites the do-file if one exists.

\hangpara
\stcmd{append} appends the code to the existing do-file.

\hangpara
\stcmd{run} specifies that the do-file created is run upon completion. This option is typically specified with most runs.

The primary intent of \stcmd{wgtcellcollapse collapse} is to create the code that can be
utilized for both the survey data file and the population targets data file that
are assumed to have identically named variables. Thus it does not only manipulate the data in the memory
and collapses the cells, but also produces the do-file code that can be recycled.
To that effect, when a do-file is created with the \stcmd{replace} and \stcmd{saving()} options,
the user needs to specify \stcmd{generate()} option to provide the name of the collapsed variable;
and when the said do-file is appended with the the \stcmd{append} and \stcmd{saving()} options,
the name of that variable is provided with the \stcmd{feed()} option.

The algorithm \stcmd{wgtcellcollapse collapse} uses to identify the cells to be collapsed is
a variation of greedy search.
It first identifies the cells with the lowest (positive) counts; finds the candidate rules
for the variable(s) to be collapsed; evaluates the counts of the collapsed cells across all 
these candidate rules; and uses the rule that has produces the smallest size of the
collapsed cell across all applicable rules. So when it finds several rules that are applicable
to the cell being currently processed that has a size of 5, and the candidate rules produce cells
of sizes 7, 10 and 15, \stcmd{wgtcellcollapse collapse} will use the rule that produces the cell
of size 7. The algorithm runs until all cells have sizes of at least
\stcmd{mincellsize(\num)} or until \stcmd{maxpass(\num)} passes through the data are executed.
It is a pretty dumb algorithm, actually, and it fails quite often. 
For that reason, a number of hooks are provided to modify its behavior.
Section \ref{subsec:example} will demonstrate the typical failures, and the ways to overcome them.

\textit{Hint 1}. Since \stcmd{wgtcellcollapse collapse} works with the sample data,
it will not be able to identify categories that are not observed in the sample (e.g., rare categories),
but may be present in the population. This will lead to errors at the raking stage,
when the control total matrices have more categories than the data, forcing \stcmd{ipfraking} to stop.
To help with that, the option \stcmd{zeroes()} allows the user to pass the categories
of the variables that are known to exist in the population but not in the sample.

\textit{Hint 2}. The behavior of \stcmd{wgtcellcollapse collapse, zeroes()} may still not be
satisfactory. As it evaluates the sample sizes of the collapsed cells across a number
of candidate rules that involve zero cells, it will probably pick up the rule with lowest
number, and that rule may as well leave some other candidate rules with zero cells untouched.
This may create problems when \stcmd{wgtcellcollapse collapse} returns to those untouched cells,
and looks for the existing cells to collapse them with, creating collapsing rules with breaks
in the sequences. To improve upon that behavior, option \stcmd{greedy} makes
\stcmd{wgtcellcollapse collapse} look for a rule that has as many categories as possible, thus collapsing
as many categories with zero counts in one swipe as it can.

\textit{Hint 3}. Other than for dealing with zero cells, the option \stcmd{strict} should be specified
most of the times. It effectively makes sure that the candidate rules correspond to the actual data.

\textit{Hint 4}. Sometimes, you see some combinations in the data that seem like a nobrainer
to collapse. Well, they are nobrainers to you, but \stcmd{wgtcellcollapse collapse} is not that smart.
If you want to guarantee some specific combination of cells to be collapsed by \stcmd{wgtcellcollapse collapse},
your best bet may be to explicitly identify them with the \ifexp\ condition, and specify some
ridiculously large cell size like \stcmd{mincellsize(10000)} so that \stcmd{wgtcellcollapse collapse} makes every possible
effort to collapse those cells. It will exit with a complaint that this size could not be achieved,
but hopefully the cells will be collapsed as needed.

\subsection{Motivating example}
\label{subsec:example}

Development of \stcmd{wgtcellcollapse} was to address the need
to collapse cells of the margin variables so that each cell has a minimum sample size;
and to do so in a way that can be easily made consistent between the sample data
and the population targets data. The problem arises when some of the target
variables have dozens of categories, most of which have small counts.
While the primary motivation comes from transportation surveys,
the ideas are also applicable to other domains, e.g.,
continuous age variables or highly detailed race/ethnicity or region of origin
categories in health or economic surveys.

The workflow of \stcmd{wgtcellcollapse} is demonstrated with the following
simulated data set of trips along a metro line composed of 21 stations:

\begin{stlog}
\input{ipfr.trip.sta.log.tex}\nullskip
\end{stlog}

Turnstile counts were collected at entrances and exits of the stations, producing the following
population figures.

\noindent
\begin{stlog}
\input{ipfr.trip.pop.log.tex}\nullskip
\end{stlog}

A survey was administered to a sample of the metro line users, with the following counts
of cases collected.

% make this a table?

\noindent
\begin{stlog}
\input{ipfr.trip.samp.log.tex}\nullskip
\end{stlog}

As only \input{sample.size.tex}\nullskip surveys were collected from a total of
\input{pop.size.tex}\nullskip riders, we would reasonably expect
that things do not align quite well. We expect weighting to correct for at least a portion of
that nonresponse. The data available for calibration includes the population turnstile counts
listed above, and we will produce interactions of daypart and station that will serve as two
weighting margins (one for the stations where the metro users boarded, and one for the stations
where they got off).

First, we need to define the weighting rules. In this case, the stations are numbered sequentially,
with the northernmost, say, station Alewife being number 3, and the southernmost station,
Union Station, where everybody gets off to rush to their city jobs or attractions, being number 69.
Below, we create a list of stations and provide it to \stcmd{wgtcellcollapse sequence}.
We would be collapsing stations along the line, with the expectation that travelers boarding or leaving
at adjacent stations within the same day part are more similar to one another than the travelers
boarding or leaving a particular station at different times of the day. Collapsing rules
need to be defined for the \stcmd{daypart} variable as well --- mostly because \stcmd{wgtcellcollapse collapse}
expects all variables to have collapsing rules defined.

\begin{stlog}
\input{ipfr.trip.rule.log.tex}\nullskip
\end{stlog}

The number of collapsing rules for variables \stcmd{board\_id} and \stcmd{alight\_id}
created by \stcmd{wgtcellcollapse sequence}
is \input{station.nrules.tex}\nullskip each.

\subsubsection{The first pass of cell collapse and raking}

Let us say that we want to define weighting cells with at least 20 cases in each.
We will thus start with weighting cells defined as station-by-daypart interaction,
and collapsing stations within daypart to achieve the cell sizes of at least 20 cases.
Here is what a simple run of \stcmd{wgtcellcollapse collapse} might look like.

\begin{stlog}
\input{ipfr.trip.att1.log.tex}\nullskip
\end{stlog}

The collapsed values of the variables \stcmd{dpston} (DayPart-STation-ON) and
\stcmd{dpstoff} (DayPart-STation-OFF) combine the values of the parent variables. The value
of \stcmd{dpston==1000003} indicates \stcmd{daypart==1} and station ID 3.
The value of \stcmd{dpston==2065270} indicates \stcmd{daypart==2} and sequence of
six stations from 52 to 70.
\label{page:dpston:nomenclature}

Note that \stcmd{wgtcellcollapse} returns a list of the cells that it could not
collapse in \stcmd{r(failed)} macro (and a comma delimited list, in \stcmd{f(cfailed)}).
These returned values should be used in production code by making an \stcmd{assert}
\citep{gould:2003:tip3} that these macros are empty.
While we know that some cell counts are less than 20, we will ignore the issue
for the moment, as there are bigger concerns with the collapsed cells at the moment,
as will become clear once we follow through with the workflow and attempt raking.

From the above run, \stcmd{wgtcellcollapse} produced two files, one for each
weighting margin, called \stcmd{dpston.do} and \stcmd{dpstoff.do}. An interested reader
is welcome to \stcmd{list} them; they contain long sequences of \stcmd{replace}
commands to perform the cell collapsing. The point of creating these is that they
can be run on the population data to create identical categories:

\begin{stlog}
\input{ipfr.trip.pop1.log.tex}\nullskip
\end{stlog}

Once that is done, we can go back to the sample data and try to create raking weights:

\begin{stlog}
\input{ipfr.trip.rake1.log.tex}\nullskip
\end{stlog}

We see that raking failed, because survey nonresponse wiped out some of the smaller
stations from the sample. (Note also the informative error message with
diagnostics of missing categories produced by \stcmd{ipfraking}. This is a functionality
added since the first 2010 publication in \textit{The Stata Journal}. The message lists
the categories found in the data, in the control totals, and in the mismatch.)

\subsubsection{The second pass of cell collapse and raking: \stcmd{zeroes()} option}

Having identified the issue, we can overcome it with \stcmd{zeroes()} option
of \stcmd{wgtcellcollapse collapse} whose purpose is specifically to add missing categories.
This option provides the list of stations that may have zero sample counts
in a given daypart.
For instance, notice that the sample registers only one alighting at Brookline (2)
in AM Peak daypart, even though there are passengers exiting in other dayparts. All in all,
\stcmd{wgtcellcollapse} needs to be made aware of the zero sample boardings at
Johnsville (39), King Street (40), Limerick (44), Ninth Street (49),
Queens Zoo (55) and Redline Circle (60); as well as zero alightings at Brookline (2),
Carmenton (8), Irvingtown (36),
Johnsville (39), King Street (40), Limerick (44), Moscow City (47), Ninth Street (49),
Ontario Lake (50), Queens Zoo (55), Redline Circle (60), and Silver Spring (62).

\begin{stlog}
\input{ipfr.trip.att2.log.tex}\nullskip
\end{stlog}

We will continue to disregard the cell counts of insufficient size for the time being.
Running the resulting do-files \stcmd{dpston.do} and \stcmd{dpstoff.do}
on the population data to create control totals, and providing these control totals
to \stcmd{ipfraking} program produces an apparently successful raking result:

\begin{stlog}
\input{ipfr.trip.rake2.log.tex}\nullskip
\end{stlog}

Note the use of utility program \stcmd{whatsdeff} to compute the design effect
due to unequal weighting; see section \ref{subsec:utility}. The problem of zero cells
appeared to have been solved: each and every population combination of daypart and station
is properly reflected in control total categories, and there are

The weighting cells, however, are still not without problems. Consider this
cross-tab of original and collapsed stations (the first part of the \ifexp\ expression identifies
the daypart, AM Peak; the second part identifies collapsed stations, given the nomenclature
of \stcmd{dpstoff} variable described on page \ref{page:dpston:nomenclature} as the concatenation
of the first variable of the interaction, \stcmd{daypart}; the length of the collapsed sequence,
and its starting and end points; station numbers take up to two characters, and hence the collapsed 
values would use categories of \stcmd{alight\_id} like 20102, and \stcmd{mod} by \stcmd{100*100}
would be greater than the maximum two-digit number, 99).

\begin{stlog}
\input{ipfr.trip.overlap2.log.tex}\nullskip
\end{stlog}

To the human eye, it is obvious that Picadilly Square (53) and Queens Zoo (55) should have been
a part of the six-station sequence 1064962 spanning from Ninth Street (49) to Silver Spring (62).
Instead, \stcmd{wgtcellcollapse} decided to separate these two stations out into their own cell.
How did that happen? The logic of \stcmd{wgtcellcollapse} is to collapse categories in such a way
as to produce the result with the smallest possible count. Thus, within AM Peak daypart,
the sequence of collapsing steps was as follows.

\begin{description}
    \item[Pass 0] The zero cells were collapsed first: Johnsville (39) and King Street (40) resulting
        in an intermediate cell of size 3.
    \item[Pass 24] The smallest cell of size 1 (Brookline (2)) was collapsed with its neighbor
        (Carmenton (8)) resulting in an intermediate cell of size 12.
    \item[Pass 38] The smallest cell of size 2 (Ontario Lake (50)) was collapsed with its neighbor
        (Ninth Street (49)) resulting in an intermediate cell of size 5.
    \item[Pass 47] The smallest cell of size 3, collapsed Johnsville (39) and King Street (40),
        was further collapsed with its neighbor Irvingtown (36) resulting in an intermediate cell of size .
    \item[Pass 55] The smallest cell of size 5, Redline Circle (60), was collapsed by a three-way rule 
        with a duo Picadilly Square (53) + Queens Zoo (55), which actually was empty, and a small cell 
        Ontario Lake (50) + Ninth Street (49), resulting in an intermediate cell of size 10.
\end{description}

Let us look at that last step in more detail. At this stage, Redline Circle (60) with 5 exiting passengers in
the sample could be collapsed with:
\begin{enumerate}
    \item Silver Spring (62), to form a cell of size 54;
    \item Queens Zoo (55), to form a cell of size 11;
    \item a sequence of Picadilly Square (53) and Queens Zoo (55), to form a cell of size 34;
    \item \ldots and many other options
\end{enumerate}
However, at pass 55, \stcmd{wgtcellcollapse} picked the rule 24950:25355:60=54960 which, at the time it was
processed, had a count of 5 in the cell 24950, a count of zero in the cell 25355, and a count of 5 in the
original station Redline Circle (60). (Note that the cell 25355 would actually form eventually at pass 58.)
The problem lies with the zero count of the ghost of the cell 25355.

To overcome this problem, \stcmd{wgtcellcollapse} have a \stcmd{strict} option that only allows the rules
that have a non-zero count in every component of the rule (so 24950:25355:60=54960 would not be a legal
merge under that option). As is easily seen, this option directly contradicts the \stcmd{zeroes()} option,
and that necessitates separate runs.

\subsubsection{The third pass of cell collapse and raking: \stcmd{strict} and \stcmd{feed} options}

We will separate the two runs of \stcmd{wgtcellcollapse} into a run that only deals with zeroes,
and another run that deals with everything else. To prevent \stcmd{wgtcellcollapse} from any further
merges, \stcmd{mincellsize(1)} can be specified in the first run. As the relevant variables will have already been
created by the first run, the option to pass the variable name to be further modified is
\stcmd{feed()}. To make sure that the relevant variable exists in the data set,
the option \stcmd{run} instructs \stcmd{wgtcellcollapse} to run the do-file it just created,
thus creating or modifying the collapsed cell variable.
Finally, instead of specifying \stcmd{replace} to overwrite the do-files that 
\stcmd{wgtcellcollapse} creates, we need to specify \stcmd{append} to keep adding to these files.

\begin{stlog}
\input{ipfr.trip.att3.log.tex}\nullskip
\end{stlog}

The result still isn't satisfactory, as some collapsed rules still overlap:

\begin{stlog}
\input{ipfr.trip.overlap3.log.tex}\nullskip
\end{stlog}

This overlap can be traced back to the collapsing of zero cells:
first, the cell 2023036 came to being by a reasonable, at its face, collapsing 
of the zero cell Irvingtown (36) with non-zero cell High Point (30);
and then the cell 2042639 came to being by a long overreach for the zero cell
Johnsville (39) to be collapsed with a non-zero cell Grand Junction (26).

\subsubsection{The fourth pass of cell collapse and raking: \stcmd{greedy} and \stcmd{maxcat()} options}

The process can be improved with an additional option \stcmd{greedy} that is applicable mostly
to the collapsing of zero cells. It modifies behavior of \stcmd{wgtcellcollapse} to require that,
among the possible candidate rules with the lowest count, the rule with the \textit{greatest} number 
of components is preferred. That way, the long streaks of zeroes from Irvingtown (36) to Limerick (44) in
midday part could be collapsed simultaneously into one cell. To support this option, and avoid complex collapses
of zero cells with the already defined cells, option \stcmd{maxcategory()} specifies the greatest
value of a component of a rule. By specifying \stcmd{maxcategory(99)}, we can instruct \stcmd{wgtcellcollapse}
to only use rules that deal with individual stations, and do not use the rules that involve collapsed
cells (which would have numbers of at least 20102 for the collapsed cell Alewife (1) and Brookline (2)).
In the first run, those collapsed cells will always be empty ghosts, and they should not be used.

Note also that with the \stcmd{greedy} option, one would want to specify the zeroes somewhere in the middle
of the streak, and possibly across multiple categories of the interacting variable. In our example,
specifying \stcmd(zeroes(36)} would collapse the midday streak of zero counts, but the need to collapse
the zeroes in the night and the weekend dayparts would still remain, necessitating something like
\stcmd{zeroes(40)} --- which, in turn, will likely create overlapping artifacts in the midday section.
However, specifying \stcmd{zeroes(40)} without \stcmd(zeroes(36)} would take care of all the streaks
observed in Table \ref{tab:sample:xtab}.

\begin{stlog}
\input{ipfr.trip.att4.log.tex}\nullskip
\end{stlog}

We have finally been able to produce a clean collapse of everything! Note the use of 
\stcmd{assert "`r(failed)'"==""} in the above code snippet to make sure that all cells have 
the minimal required size of 20.

As a very minor point, we can see some room for improvement in collapsing the cells on the weekend:

\begin{stlog}
\input{ipfr.trip.improve4.log.tex}\nullskip
\end{stlog}

Instead of two cells with sizes 141 and 32, it seems like we could produce three cells, with
Union Station (69) being its own cell, and everything else split somewhere in the middle.

\subsubsection{The fifth pass of cell collapse and raking: \ifexp\ conditions}

We will now code the collapsing cells for that day part ``by hand'', and we will put those
custom coded cells upfront before the main run. (Some special treatment had to be given
to the zero cells to avoid overlapping cells around Ninth Street (49) for the night and weekend
day parts; without the separation, it is getting collapsed in a long overreach all the way up to
Redline Circle (60).)

\begin{stlog}
\input{ipfr.trip.att5.log.tex}\nullskip
\end{stlog}

Checking on the last improvement, we see how the manual resolution succeeded:

\begin{stlog}
\input{ipfr.trip.improve5.log.tex}\nullskip
\end{stlog}

The resulting do-files can now be applied to producing control totals, and eventually to raking:

\begin{stlog}
\input{ipfr.trip.rake5.log.tex}\nullskip
\end{stlog}

\subsubsection{Informative labels}
\label{subsec:wgtcellcollapse:labels}

As the final touch, let us consider the variety of labels that can be attached to the resulting
collapsed cells.

\begin{stlog}
\input{ipfr.trip.label5.log.tex}\nullskip
\end{stlog}

Using the mechanics of labels in multiple languages, \stcmd{wgtcellcollapse label} defines three
``languages'' to describe the cells. The language \stcmd{numbered\_ccells} may be convenient
for debugging purposes in fine-tuning the collapsing algorithms, while the language
\stcmd{texted\_ccells} would prove useful for \stcmd{ipfraking\_report} in creating human-readable
labels.

\section{Linear calibrated weights}
\label{subsec:linear}

Using the existing example, let me demonstrate the linear calibration option of 
\stcmd{ipfraking}.

\begin{stlog}
\input{ipfr.trip.lin5.log.tex}\nullskip
\end{stlog}

\begin{figure}[h!]
    \begin{center}
    \epsfig[scale=0.2]{file=raked_linear}
    \end{center}
    \caption{Linear and raked weights}
    \label{fig:linear:raked}
\end{figure}

The speed advantages of \stcmd{linear} calibration are quite clear, even though
convergence of raking in 8 iterations is lighting-fast, in author's experience. 
The weights are very similar to one another, with the lowest of the linearly
calibrated weights being slightly smaller than comparable raked weights.
As mentioned before, in the extreme situations, linearly calibrated weights
may become negative.


















\section*{Acknowledgements}

The author is grateful to Jason Brinkley and Tom Guterbock for bug reports and 
functionality suggestions.
The opinions stated in this paper
are of the author only, and do not represent the position of Abt Associates.

\bibliographystyle{sj}
\bibliography{everything}
% \bibliography{ipfraking}

\begin{aboutauthor}
  Stanislav (Stas) Kolenikov is a Senior Scientist at Abt Associates.
  His work involves applications of statistical methods in data collection
  for public opinion research, public health, transportation, and other disciplines
  that utilize collection of survey data.
  Within survey methodology, his expertise includes advanced sampling techniques,
  survey weighting, calibration, missing data imputation, variance estimation,
  nonresponse analysis and adjustment, small area estimation, and mode effects.
  Besides survey statistics, Stas has extensive experience developing and applying
  statistical methods in social sciences, with focus on structural equation
  modeling and microeconometrics. He has been writing Stata programs since
  1998 when Stata was version 5.
\end{aboutauthor}
