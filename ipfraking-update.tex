\inserttype[st0001]{article}
\author{S. Kolenikov}{%
  Stanislav Kolenikov\\Abt Associates\\stas\_kolenikovs@abtassoc.com
}
\title[Raking survey data: updates]{Updates to the ipfraking ecosystem}
\maketitle

\begin{abstract}
\citet{kolenikov:2014} introduced package \stcmd{ipfraking}
for weight calibration procedures known as iterative proportional fitting,
or raking, of complex survey weights.
This article briefly describes the original package,
and adds updates to the core program, as well as a host of
additional programs that are used to support the process of creating
survey weights in the authors' production code.

\keywords{\inserttag, survey, calibration, weights, raking}
\end{abstract}

\section{Introduction and background}

Large scale social, behavioral and health data are often collected
via complex survey designs that may involve some or all of stratification,
multiple stages of selection and unequal probabilities of selection
\citep{korn:graubard:1995,korn:graubard:1999}.
In an ideal setting, varying probabilities of selection are
accounted for by using the Horvitz-Thompson estimator of the totals
\citep{horvitz:thompson:1952,thompson:1997}, and the remaining
sampling fluctuations can be further ironed out by
post-stratification \citep{holt:smith:1979}.
However, on top of the planned differences in probabilities of obtaining
a response from a sampled unit, non-response is a practical problem
that has been growing more acute over the recent years
\citep{groves:dillman:eltinge:little:2001,pew:2012}.
The analysis weights that are provided along with the public use
microdata by data collecting agencies are designed to account
for unequal probabilities of selection, non-response, and other factors
affecting imbalance between the population and the sample, thus making
the analyses conducted on such microdata generalizable to the target population.

Earlier, I introduced \citep{kolenikov:2014} a Stata package
called \stcmd{ipfraking} that implements
calibration of survey weights to known control totals to ensure
that the resulting weighted data are representative of the population
of interest. The process of calibration is aimed at aligning the sample totals
of the key variables with those known for the population as a whole.
The remainder of this section provides a condensed treatment of estimation
with survey data using calibrated weights; full treatment was provided
in the original paper.

For a given finite population $\mathcal U$ of units indexed $i=1,\ldots,N$,
the interests of survey statisticians often lie in estimating the
population total of a variable $Y$
\begin{equation}
   T[Y] = \sum_{i \in \mathcal{U}} Y_i
   \label{eq:total:pop}
\end{equation}
A sample $\mathcal S$ of $n$ units indexed by $j=1,\ldots,n$
is taken from $\mathcal U$. If the probability to select the
$i$-th unit is known to be $\pi_i$, then
the {\it probability weights}, or {\it design weights}, are given by
the inverse probability of selection:
\begin{equation}
   w_{1i} = \pi_i^{-1}
   \label{eq:prob:weight}
\end{equation}
With these weights, an unbiased
(design-based, non-parametric) estimator
of the total (\ref{eq:total:pop}) is \citep{horvitz:thompson:1952}
\begin{equation}
   t_{1}[y] = \sum_{j \in \mathcal{S}} \frac{y_j}{\pi_j}
   \equiv \sum_{j \in \mathcal{S}} w_{1j} y_j
   \label{eq:total:sample},
\end{equation}
The subindex $1$ indicates that the weights $w_{1i}$ were
used in obtaining this estimator. Probability weights protect
the end user from potentially informative sampling designs, in which
the probabilities of selection are correlated with outcomes, and
the design-based methods generally ensure that inference can be generalized
to the finite population even when the statistical models used
by analysts and researchers are not specified correctly
\citep{pfeff:1993,binder:roberts:2003}.

Often, survey statisticians have auxiliary information on the units
in the frame, and such information can be included it at the sampling stage
to create more efficient designs. Unequal probabilities of selection
are then controlled with probability weights, implemented
as \stcmd{[pw=}{\it exp}\stcmd{]} in Stata (and can be permanently
affixed to the data set with \stcmd{svyset} command).

In many situations, however, usable information is not available beforehand,
and may only appear in the collected data. The census totals of the age and gender
distribution of the population may exist, but age and gender of
the sampled units is unknown until the survey measurement is taken on them.
It is still possible to capitalize on this additional data by
adjusting the weights in such a way that the reweighted data
conforms to these known figures. The procedures to perform these
reweighting steps are generally known as {\it weight calibration}
\citep{deville:sarndal:1992,deville:sarndal:sautory:1993,%
kott:2006,kott:2009,sarndal:2007}.

Suppose there are several (categorical) variables, referred to
as {\it control variables}, that are available for both
the population and the sample
(age groups, race, gender, educational attainment, etc.).
Weight calibration aims at adjusting the margins, or low level interactions,
via an iterative optimization aimed at satisfying
the {\it control totals} for the control variables $\mathbf{x}=(x_1, \ldots, x_p)$:
\begin{equation}
    \sum_{j \in \mathcal{S}} w_{3j} \mathbf{x}_j
    = T [ \mathbf{X}_j  ]
    \label{eq:control:totals}
\end{equation}
where the right hand side is assumed to be known from a census or
a higher quality survey.
\citet{deville:sarndal:1992} framed the problem of finding a suitable
set of weights as that of constrained optimization with the control
equations (\ref{eq:control:totals}) serving as constraints,
and optimization targeted at making the discrepancy between
the design weights $w_{1j}$ and calibrated weights
$w_{3j}$ as close as possible, in a suitable sense.

In package \stcmd{ipfraking} \citep{kolenikov:2014}, I implemented
a popular calibration algorithm, known as \textit{iterated proportional fitting},
or as \textit{raking}, which consists of iterative updating (post-stratification) of
each of the margins. (For an in-depth discussion of distinctions between
raking and post-stratification, see \citet{kolenikov:2016}.)
Since 2014, the continuing code development resulted
in additional features that this update documents.

\section{Package description}

Below, I provide full syntax, and list the new features in a dedicated section.

\subsection{Syntax of \stcmd{ipfraking}}
\label{subsec:syntax}

\begin{stsyntax}
ipfraking
\optif\
\optin\
\optweight\
,
\underbar{ctot}al({\it matname} [{\it matname \ldots}])
\optional{
\underbar{gen}erate(\newvarname)
replace
double
\underbar{iter}ate(\num)
\underbar{tol}erance(\num)
\underbar{ctrltol}erance(\num)
trace
\underbar{nodiv}ergence
trimhiabs(\num)
trimhirel(\num)
trimloabs(\num)
trimlorel(\num)
trimfrequency(once|sometimes|often)
double
meta
nograph
}
\end{stsyntax}

\hangpara
Note that the weight statement \stcmd{[pw=\varname]} is required, and must contain the initial weights.

\subsubsection{Required options}

\hangpara
\stcmd{\underbar{ctot}al(}{\it matname} \LB{\it matname \ldots}\RB\stcmd{)}
supplies the names of the matrices that contain the control
totals, as well as meta-data about the variables to be used
in calibration.

\begin{sttech}
The row and column names of the control total matrices
(see \pref{matrix rownames}) should be formatted as follows.
\begin{itemize}
    \item \stcmd{rownames}: the name of the control variable
    \item \stcmd{colnames}: the values the control variables takes
    \item \stcmd{coleq}: the name of the variable for which total is computed;
          typically it is identically equal to 1.
\end{itemize}
See examples in Section \ref{sec:examples}.
\end{sttech}

\hangpara
\stcmd{\underbar{gen}erate(\newvarname)}
contains the name of the new variable to contain the raked weights.

\hangpara
\stcmd{replace} indicates that the weight variable supplied in the
\stcmd{[pw=\varname]} expression should be overwritten with the new weights.

One and only one of \stcmd{generate()} or \stcmd{replace} must be specified.

\subsubsection{Linear calibration}

\hangpara
\stcmd{\underbar{lin}ear}
requests linear calibration of weights.

\subsubsection{Options to control convergence}

\hangpara
\stcmd{\underbar{tol}erance(\num)} defines convergence criteria
(the change of weights from one iteration to next). The default is $10^{-6}$.

\hangpara
\stcmd{\underbar{iter}ate(\num)} specifies the maximum number
of iterations. The default is 2000.

\hangpara
\stcmd{\underbar{nodiv}ergence} overrides the check
that the change in weights is greater at the current iteration
than in the previous one, i.e., ignores this termination condition.
It is generally recommended, especially in calibration with simultaneous trimming.

\hangpara
\stcmd{\underbar{ctrltol}erance(\num)} defines the criterion to
assess the accuracy of the control totals. It does not impact
iterations or convergence criteria, but rather only triggers alerts in the output.
The default value is $10^{-6}$.

\hangpara
\stcmd{trace} requests a trace plot to be added.

\subsubsection{Trimming options}
\label{subsubsec:trimming}

\hangpara
\stcmd{trimhiabs(\num)} specifies the upper bound $U$ on the greatest
    value of the raked weights.  The weights that
    exceed this value will be trimmed down, so that
    $w_{3j} \le U$ for every $j\in\mathcal{S}$.

\hangpara
\stcmd{trimhirel(\num)} specifies the upper bound $u$ on the adjustment
    factor over the baseline weight. The weights
    that exceed the baseline times this value will be trimmed down,
    so that $w_{3j} \le u w_{1j}$ for every $j\in\mathcal{S}$.

\hangpara
\stcmd{trimloabs(\num)} specifies the lower bound $L$ on the smallest value
    of the raked weights.  The weights that are smaller than this value will
    be increased, so that $w_{3j} \ge L$ for every $j\in\mathcal{S}$.

\hangpara
\stcmd{trimlorel(\num)} specifies the lower bound $l$ on the adjustment factor
    over the baseline weight.  The weights that are smaller than the baseline
    times this value will be increased, so that
    $w_{3j} \ge l w_{1j}$ for every $j\in\mathcal{S}$.

\hangpara
\stcmd{trimfreqency({\it keyword})} specifies when the trimming operations
    are to be performed. The following keywords are recognized:

\morehang \stcmd{often} means that trimming will be performed
    after each marginal adjustment.

\morehang \stcmd{sometimes} means that trimming will be performed
    after a full set of variables has been used for post-stratification.
    This is the default behavior if any of the numeric trimming
    options above are specified.

\morehang \stcmd{once}
    means that trimming will be performed after the raking process
    is declared to have converged.

The numeric trimming options \stcmd{trimhiabs(\num)}, \stcmd{trimhirel(\num)},
\stcmd{trimloabs(\num)}, \stcmd{trimlorel(\num)} can be specified in any combination,
or entirely omitted to produce untrimmed weights. By default, there is no trimming.

\subsubsection{Miscellaneous options}

\hangpara
\stcmd{double} specifies that the new variable named in \stcmd{generate()}
option should be generated as double type. See \dref{data types}.

\hangpara
\stcmd{meta} puts information taken by \stcmd{ipfraking} as inputs and produced
    throughout the process into characteristics stored with the variable specified in
    \stcmd{generate()} option. See Section \ref{subsec:example:meta}.

\hangpara
\stcmd{nograph} omits the histogram of the calibrated weights, which can be
used to speed up \stcmd{ipfraking} (e.g., in replicate weight production).

\subsection{New features of \stcmd{ipfraking}}

Since the first publication, the following features and options were added.

Reporting of results and errors by \stcmd{ipfraking} was improved in several directions.
\begin{enumerate}
    \item The discrepancy for the worst fitting category is now being reported.
    \item The number of trimmed observations is reported.
    \item If \stcmd{ipfraking} determines that the categories do not match
        in the control totals received from \stcmd{ctotals()} and those found in
        the data, a full listing of categories is provided, and the categories
        not found in one or the other are explicitly shown.
\end{enumerate}

Linear calibration (Case 1 of \citet{deville:sarndal:1992}) is provided with
\stcmd{linear} option. The weights are calculated analytically:
\begin{equation}
    \label{eq:linear:weight}
    w_{j,\rm{lin}} = w_{1j} (1+\mathbf{x}_j'\mathbf{\lambda}).
    \quad
    \mathbf{\lambda} = \Bigl( \sum_{j \in \mathcal{S}} w_{1j} \mathbf{x}_j \mathbf{x}_j' \Bigr)^{-1}
        ( T [ \mathbf{X}_j  ] - t_{1}[y] )
\end{equation}
This works very fast, but has an undesirable artefact of producing negative weights,
as the range of weights is not controlled. (As raking works by multiplying the currents
weights by positive factors, if the input weights are all positive, the output weights
will be positive as well.) Negative weights are not allowed by the official \stcmd{svy} commands
or commands that work with \stcmd{[pweights]}.
In author's experience, running linear weights first,
pulling up the negative and small positive weights (\stcmd{replace weight = 1 if weight <= 1})
and re-raking using the ``proper'' iterative proportional fitting runs faster than
raking from scratch. An example of linearly calibrated weights is given below
in Section \ref{subsec:linear}.

Option \stcmd{meta} saves more information in characteristics of the calibrated
weight variables.

\cnp

\begin{stlog}
\input{ipfr.example5.log.tex}\nullskip
\end{stlog}

The following characteristics are stored with the newly created weight variable
(see \pref{char}).

\begin{tabular}{ll}
    \stcmd{command} & The full command as typed by the user \\
    {\it matrix name} & The relative matrix difference from the corresponding \\
                    & control total, see \dref{functions} \\
    \stcmd{trimhiabs}, \stcmd{trimloabs}, & Corresponding trimming options,
                    if specified \\
    \stcmd{trimhirel}, \stcmd{trimlorel}, & \\
    \stcmd{trimfrequency} & \\
    \stcmd{maxctrl} & the greatest \stcmd{mreldif} between the targets and the achieved \\
                    & weighted totals \\
    \stcmd{objfcn}  & the value of the relative weight change at exit \\
    \stcmd{converged} & whether \stcmd{ipfraking} exited due to convergence (1) \\
                    & vs. due to an increase in the objective function \\
                    & or reaching the limit on the number of iterations (0) \\\
    \stcmd{source}  & weight variable specified as the \stcmd{[pw=]} input \\
    \stcmd{worstvar}& the variable in which the greatest discrepancy between \\
                    & the targets and the achieved weighted totals \\
                    & (\stcmd{maxctrl}) was observed \\
    \stcmd{worstcat}& the category of the \stcmd{worstvar} variable in which the  \\
                    & greatest discrepancy was observed
\end{tabular}

For the control total matrices \num$=1,2,\ldots$, the following
meta-information is stored.

\begin{tabular}{ll}
    \stcmd{mat\num} & the name of the control total matrix \\
    \stcmd{totalof\num}& the multiplier variable (matrix' \stcmd{coleq} \\
    \stcmd{over\num}& the margin associated with the matrix \\
                    & (i.e., the categories represented by the columns)
\end{tabular}

Also, \stcmd{ipfraking} stores the notes regarding the control matrices
used, and which of the margins did not match the control totals, if any.
See \dref{notes}.

\subsection{Excel reports on raked weights:  \stcmd{ipfraking\_report}}

\begin{stsyntax}
ipfraking\_report
using \textit{filename}
,
raked\_weight(\varname)
\optional{
matrices(\textit{namelist})
by(\varlist)
xls
replace
force
}
\end{stsyntax}

The utility command \stcmd{ipfraking\_report} produces a detailed report
describing the raked weights, and places it into \textit{filename}\stcmd{.dta} file
(or, if \stcmd{xls} option is specified, both \textit{filename}\stcmd{.dta} and \textit{filename}\stcmd{.xls}
files).

Along the way, \stcmd{ipfraking\_report} runs a regression of the log raking ratio $w_{3j}/w_{1j}$
on the calibration variables. This regression is expected to have $R^2$ very close to 1,
and the regression coefficients provide insights regarding which categories received
greater vs. smaller adjustments.

\cnp

\begin{stlog}
\input{ipfr.report1.log.tex}\nullskip
\end{stlog}

\subsubsection{Options of \stcmd{ipfraking\_report}}

\hangpara
\stcmd{raked\_weight(\varname)} specifies the name of the raked weight variable to create
    the report for. This is a required option.

\hangpara
\stcmd{matrices(\textit{namelist})} specifies a list of matrices (formatted as the matrices
    supplied to \stcmd{ctotal()} option of \stcmd{ipfraking}) to produce weighting reports for.
    In particular, the variables and their categories are picked up from these matrices;
    and the control totals/proportions are compared to those defined by the weight being reported on.

\hangpara
\stcmd{by(\varlist)} specifies a list of additional variables for which the weights are to
    be tabulated in the raking weights report. The difference with the \stcmd{matrices()} option
    is that the control totals for these variables may not be known (or may not be relevant).
    In particular, \stcmd{by(\_one)}, where \stcmd{\_one} is identically one, will produce
    the overall report.

\hangpara
\stcmd{xls} requests exporting the report to an Excel file.

\hangpara
\stcmd{replace} specifies that the files produced by \stcmd{ipfraking\_report} (i.e., the \stcmd{.dta}
    and the {\stmcd{.xls}} file if \stcmd{xls} option is specified) should be overwritten.

\hangpara
\stcmd{force} requires that a variable that may be found repeatedly (between the calibration variables
    supplied originally to \stcmd{ipfraking}, the variables found in the independent total \stcmd{matrices()},
    and the variables without the control totals provided in \stcmd{by()} option) is processed every
    time it is encountered. (Otherwise, it is only processed once.)

\subsubsection{Variables in the raking report}

The following variables are saved in the raking report.

\cnp

\begin{tabular}{ll}
  \hline
  Variable name & Definition \\
  \hline
  \stcmd{Weight\_Variable} & The name of the weight variable, \stcmd{generate()} \\
  \stcmd{C\_Total\_Margin\_Variable\_Name} & The name of the control margin, \\
            & \stcmd{rowname} of the corresponding \stcmd{ctotal()} matrix \\
  \stcmd{C\_Total\_Margin\_Variable\_Label} & The label of the control margin variable \\
  \stcmd{Variable\_Class} & The role of the variable in the report: \\
        & Raking margin: a variable used as a calibration margin \\
        & (picked up automatically from the \stcmd{ctotal()} \\
        & matrix, provided \stcmd{meta} option was specified) \\
        & Other known target: supplied with \stcmd{matrices()} \\
        & option of \stcmd{ipfraking\_report} \\
        & Auxiliary variable: additional variable supplied \\
        & with \stcmd{by()} option of \stcmd{ipfraking\_report} \\
  \stcmd{C\_Total\_Arg\_Variable\_Name} & The name of the multiplier variable \\
  \stcmd{C\_Total\_Arg\_Variable\_Label} & The label of the multiplier variable \\
  \stcmd{C\_Total\_Margin\_Category\_Number} & Numeric value of the control total category \\
  \stcmd{C\_Total\_Margin\_Category\_Label} &  Label of the control total category \\
  \stcmd{Category\_Total\_Target} & The control total to be calibrated to \\
        & (the specific entry in the \stcmd{ctotal()} matrix) \\
  \stcmd{Category\_Total\_Prop} & Control total proportion \\
        & (the ratio of the specific entry in the \stcmd{ctotal()} \\
        & matrix to the matrix total) \\
  \stcmd{Unweighted\_Count} & Number of sample observations in the category \\
  \stcmd{Unweighted\_Prop} & Unweighted proportion \\
  \stcmd{Unweighted\_Prop\_Discrep} & Difference \stcmd{Unweighted\_Prop} - \stcmd{Category\_Total\_Prop} \\
  \stcmd{Category\_Total\_SRCWGT} & Weighted category total, with source weight \\
  \stcmd{Category\_Prop\_SRCWGT} & Weighted category proportion, with source weight \\
  \stcmd{Category\_Total\_Discrep\_SRCWGT} & Difference \stcmd{Category\_Total\_SRCWGT} - \\
        & - \stcmd{Category\_Total\_Target} \\
  \stcmd{Category\_Prop\_Discrep\_SRCWGT} & Difference \stcmd{Category\_Prop\_SRCWGT} - \\
        & - \stcmd{Category\_Total\_Prop} \\
  \stcmd{Category\_RelDiff\_SRCWGT} & \stcmd{reldif(Category\_Total\_SRCWGT,} \\
        & \stcmd{Category\_Total\_Target)} \\
  \stcmd{Overall\_Total\_SRCWGT} & Sum of source weights \\
  \stcmd{Source} & The name of the matrix from which the totals \\
        & were obtained \\
  \stcmd{Comment} & Placeholder for comments, to be entered during \\
        & manual review \\
  \hline
\end{tabular}

For each of the input weights (\stcmd{SRCWGT} suffix), raked weights (\stcmd{RKDWGT} suffix) and raking ratio
(the ratio of raked and input weights, \stcmd{RKDRATIO} suffix), the following summaries are provided.

\begin{tabular}{ll}
  \hline
  Variable name & Definition \\
  \hline
  \stcmd{Min\_\textit{WEIGHT}} & Min of source weights \\
  \stcmd{P25\_\textit{WEIGHT}} & 25th percentile of source weights \\
  \stcmd{P50\_\textit{WEIGHT}} & Median of source weights \\
  \stcmd{P75\_\textit{WEIGHT}} & 75th percentile of source weights \\
  \stcmd{Max\_\textit{WEIGHT}} & Max of source weights \\
  \stcmd{Mean\_\textit{WEIGHT}} & Mean of source weights \\
  \stcmd{SD\_\textit{WEIGHT}} & Standard deviation of source weights \\
  \stcmd{DEFF\_\textit{WEIGHT}} & Apparent UWE DEFF of source weights \\
  \hline
\end{tabular}

\subsubsection{Example}

\begin{stlog}
\input{ipfr.report2.log.tex}\nullskip
\end{stlog}

Functionality of \stcmd{ipfraking\_report} is aimed at the manual review
of its reporting of the categories that differ the most in the output,
and the resulting report file in Excel,
although for some aspects of automated quality control, it will be useful, as well.

\subsection{Collapsing weighting cells:  \stcmd{wgtcellcollapse}}

An additional new component of \stcmd{ipfraking} package is a tool to
semi-automatically collapse weighting cells, in order to achieve
some minimal sample size.

\begin{stsyntax}
wgtcellcollapse \textit{task}
\optif\
\optin\
,
\optional{task\_options}
}
\end{stsyntax}

where \textit{task} is one of:

\hangpara
\stcmd{define} to define collapsing rules explicitly

\hangpara
\stcmd{sequence} to create collapsing rules for a sequence of categories

\hangpara
\stcmd{report} to list the currently defined collapsing rules

\hangpara
\stcmd{candidate} to find rules applicable to a given category

\hangpara
\stcmd{collapse} to perform cell collapsing

\hangpara
\stcmd{label} to label collapsed cells using the original labels after \stcmd{wgtcellcollapse collapse}

\subsection{Syntax of \stcmd{wgtcellcollapse report}}

\begin{stsyntax}
wgtcellcollapse report
,
\underbar{var}iables(\varlist)
\optional{
break
}
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iables(\varlist)} is the list of variables for which the collapsing rule are to be reported

\hangpara
\stcmd{break} requires \stcmd{wgtcellcollapse report} to exit with error when technical inconsistencies are encountered

\subsection{Syntax of \stcmd{wgtcellcollapse define}}

\begin{stsyntax}
wgtcellcollapse define
,
\underbar{var}iables(\varlist)
\optional{
from(\textit{numlist})
to(\num)
label(\ststring)
max(\num)
clear
}
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iables(\varlist)} is the list of variables for which the collapsing rule can be used

\hangpara
\stcmd{from(\textit{numlist})} is the list of categories that can be collapsed according to this rule

\hangpara
\stcmd{to(\num)} is the numeric value of the new, collapsed category

\hangpara
\stcmd{label(\ststring)} is the value label to be attached to the new, collapsed category

\hangpara
\stcmd{max(\num)} overrides the automatically determined max value of the collapsed variable

\hangpara
\stcmd{clear} clears all the rules currently defined

Individual collapsing rules can be defined as follows.

\begin{stlog}
\input{ipfr.collapse1.log.tex}\nullskip
\end{stlog}

Note how \stcmd{break} option of \stcmd{wgtcellcollapse} can be used to abort the execution
when technical deficiencies in the rules or in the data are encountered. In this case,
the label of the new category 123 was not defined, and this is considered a serious
enough deficiency to stop.

\begin{stlog}
\input{ipfr.collapse2.log.tex}\nullskip
\end{stlog}

\subsection{Syntax of \stcmd{wgtcellcollapse sequence}}


\begin{stsyntax}
wgtcellcollapse sequence
,
\underbar{var}iables(\varlist)
from(\textit{numlist})
depth(\num)
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iables(\varlist)} is the list of variables for which the collapsing rule can be used

\hangpara
\stcmd{from(\textit{numlist})} is the sequence of values from which the plausible subsequences can be constructed

\hangpara
\stcmd{depth(\num)} is the maximum number of the original categories that can be collapsed

Moderate length sequences of collapsing categories can be defined as follows.

\begin{stlog}
\input{ipfr.collapse3.log.tex}\nullskip
\end{stlog}

When creating sequential collapses, \stcmd{wgtcellcollapse sequence} uses the following mnemonics
in creating the new labels:
\begin{itemize}
    \item First comes the length of the collapsed subsequence (up to \stcmd{depth(\num)}).
    \item Then comes the starting value of the category in the subsequence (padded by zeroes as needed).
    \item Then comes the ending value of the category in the subsequence (padded by zeroes as needed).
\end{itemize}

In the example above, rules 7 through 9 lead to collapsing into the new category 324. This
should be interpreted as ``the subsequence of length 3 that starts with category 2 and ends with category 4''.
A numeric value of the collapsed category that reads like 50412 means
``the subsequence of length 5 that starts with category 4 and ends with category 12''.

Note that \stcmd{wgtcellcollapse sequence} respects the order in which the categories are
supplied in the \stcmd{from()} option, and does not sort them.

\subsection{Syntax of \stcmd{wgtcellcollapse candidate}}

\begin{stsyntax}
wgtcellcollapse candidate
,
\underbar{var}iable(\varname)
category(\num)
\optional{ \max{\num} }
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iable(\varname)} is the variable whose collapsing rules are to be searched

\hangpara
\stcmd{category(\num)} is the category for which the candidate rules are to be identified

\hangpara
\stcmd{max(\num)} is the maximum value of the categories in the candidate rules to be returned

The rules found are quietly returned through the mechanism of \stcmd{sreturn},
see \pref{return}, as they are intended to be stay in memory sufficiently long for
\stcmd{wgtcellcollapse collapse} to evaluate each rule.

\begin{stlog}
\input{ipfr.collapse4.log.tex}\nullskip
\end{stlog}

In the second call to
the option \stcmd{max(9)} was used to restrict the returned rules to the rules
that deal with the original categories only. In the third call, a list of rules
that involve a collapsed category \stcmd{cat(212)} was requested. Requests
for nonexisting categories are not considered errors, but simply produce empty lists
of ``good rules''

\subsection{Syntax of \stcmd{wgtcellcollapse collapse}}

\begin{stsyntax}
wgtcellcollapse collapse \optif \optin
,
\underbar{var}iables(\varlist)
mincellsize(\num)
\underbar{sav}ing(\textit{dofile\_name})
\optional{
\underbar{gen}erate(\newvarname)
replace
append
feed(\varname)
strict
sort(\varlist)
run
maxpass(\num)
\underbar{maxcat}egory(\num)
\underbar{zer}oes(\textit{numlist})
greedy
}
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iables(\varlist)} provides the list of variables whose cells are to be collapsed.
When more than one variable is specified, \stcmd{wgtcellcollapse collapse} proceeds from right to left,
i.e., first attempts to collapse the rightmost variable.

\hangpara
\stcmd{mincellsize(\num)} specifies the minimum cell size for the collapsed cells. For most weighting
purposes, values of 30 to 50 can be recommended.

\hangpara
\stcmd{\underbar{gen}erate(\newvarname)} specifies the name of the collapsed variable to be created.

\hangpara
\stcmd{feed(\varname)} provides the name of an already existing collapsed variable.

\hangpara
\stcmd{strict} modifies the behavior of \stcmd{wgtcellcollapse collapse} so that only
collapsing rules for which all participating categories have nonzero counts are utilized.

\hangpara
\stcmd{sort(\varlist)} sorts the data set before proceeding to collapse the cell.
The default sort order is in terms of the values of the collapsed variable.
A different sort order may produce a different set of collapsed cell when
cells are tied on size.

\hangpara
\stcmd{maxpass(\num)} specifies the maximum number of passes through the data set. The default value is 10000.}

\hangpara
\stcmd{\underbar{maxcat}egory(\num)} is the maximum category value of the variable being collapsed.
It is passed to the internal calls to \stcmd{wgtcellcollapse candidate}, see above.

\hangpara
\stcmd{\underbar{zer}oes(\textit{numlist})} provides a list of the categories of the collapsed
variable that may have zero counts in the data.

\hangpara
\stcmd{greedy} modifies the behavior \stcmd{wgtcellcollapse collapse} to prefer the rules
that collapse the maximum number of categories.

Options to deal with the do-file to write the collapsing code to:	

\hangpara
\stcmd{\underbar{sav}ing(\textit{dofile\_name})} specifies the name of the do-file that will contain the cell collapsing code.

\hangpara
\stcmd{replace} overwrites the do-file if one exists.

\hangpara
\stcmd{append} appends the code to the existing do-file.

\hangpara
\stcmd{run} specifies that the do-file created is run upon completion. This option is typically specified with most runs.

The primary intent of \stcmd{wgtcellcollapse collapse} is to create the code that can be
utilized for both the survey data file and the population targets data file that
are assumed to have identically named variables. Thus it does not only manipulate the data in the memory
and collapses the cells, but also produces the do-file code that can be recycled.
To that effect, when a do-file is created with the \stcmd{replace} and \stcmd{saving()} options,
the user needs to specify \stcmd{generate()} option to provide the name of the collapsed variable;
and when the said do-file is appended with the the \stcmd{replace} and \stcmd{saving()} options,
the name of that variable is provided with the \stcmd{feed()} option.

The algorithm \stcmd{wgtcellcollapse collapse} uses to identify the cells to be collapsed is
a variation of greedy search.
It first identifies the cells with the lowest (positive) counts; finds the candidate rules
for the variable(s) to be collapsed; and uses the rule that has produces the smallest size of the
collapsed cell across all applicable rules. So when it finds several rules that are applicable
to the cell being currently processed that has a size of 5, and the candidate rules produces cells
of sizes 7, 10 and 15, \stcmd{wgtcellcollapse collapse} will use the rule that produces the cell
of size 7. The algorithm runs until all cells have sizes of at least
\stcmd{mincellsize(\num)} or until \stcmd{maxpass(\num)} passes through the data are executed.
It is a pretty dumb algorithm, actually, and it fails quite often. For that reason,
a number of hooks are provided to modify its behavior.

\textit{Hint 1}. Since \stcmd{wgtcellcollapse collapse} works with the sample data,
it will not be able to identify categories that are not observed in the sample (e.g., rare categories),
but may be present in the population. This will lead to errors at the raking stage,
when the control total matrices have more categories than the data, forcing \stcmd{ipfraking} to stop.
To help with that, the option \stcmd{zeroes()} allows the user to pass the categories
of the variables that are known to exist in the population but not in the sample.

\textit{Hint 2}. The behavior of \stcmd{wgtcellcollapse collapse, zeroes()} may still not be
satisfactory. As it evaluates the sample sizes of the collapsed cells across a number
of candidate rules that involve zero cells, it will probably pick up the rule with lowest
number, and that rule may as well leave some other candidate rules with zero cells untouched.
This may create problems when \stcmd{wgtcellcollapse collapse} returns to those untouched cells,
and looks for the existing cells to collapse them with, creating collapsing rules with breaks
in the sequences. To improve upon that behavior, option \stcmd{greedy} makes
\stcmd{wgtcellcollapse collapse} look for a rule that has many categories as possible, thus collapsing
as many categories with zero counts in one swipe as it can.

\textit{Hint 3}. Other than for dealing with zero cells, the option \stcmd{strict} should be specified
most of the times. It effectively makes sure that the candidate rules correspond to the actual data.

\textit{Hint 4}. Sometimes, you see some combinations in the data that seem like a nobrainer
to collapse. Well, they are nobrainers to you, but \stcmd{wgtcellcollapse collapse} is not that smart.
If you want to guarantee some specific combination of cells to be collapsed by \stcmd{wgtcellcollapse collapse},
your best bet may be to explicitly identify them with the \ifexp condition, and specify some
ridiculously large cell size like \stcmd{mincellsize(10000)} so that \stcmd{wgtcellcollapse collapse} makes every possible
effort to collapse those cells. It will exit with a complaint that this size could not be achieved,
but hopefully the cells will be collapsed as needed.

\subsection{Syntax of \stcmd{wgtcellcollapse label}}

\begin{stsyntax}
wgtcellcollapse label
,
\underbar{var}iable(\varname)
category(\num)
\optional{ verbose force }
\end{stsyntax}

\hangpara
\stcmd{\underbar{var}iable(\varname)} is the collapsed variable to be labeled.

\hangpara
\stcmd{verbose} outputs the labeling results. There may be a lot of output.

\hangpara
\stcmd{force} instructs \stcmd{wgtcellcollapse label} to only use categories present in the data.

\subsubsection{Motivating example}

Development of \stcmd{wgtcellcollapse} was to address the need
to collapse cells of the margin variables so that each cell has a minimum sample size;
and to do so in a way that can be easily made consistent between the sample data
and the population targets data. The problem arises when some of the target
variables have dozens of categories, most of which have small counts.
While the primary motivation comes from transportation surveys,
the ideas are also applicable to other domains, e.g.,
continuous age variables or highly detailed race/ethnicity or region of origin
categories in health or economic surveys.

The workflow of \stcmd{wgtcellcollapse} is demonstrated with the following
simulated data set of trips along a metro line composed of 21 stations:

\begin{stlog}
\input{ipfr.trip.sta.log.tex}\nullskip
\end{stlog}

Turnstile counts were collected at entrances and exits of the stations, producing the following
population figures.

\noindent
\begin{stlog}
\input{ipfr.trip.pop.log.tex}\nullskip
\end{stlog}

A survey was administered to a sample of the metro line users, with the following counts
of cases collected.

% make this a table?

\noindent
\begin{stlog}
\input{ipfr.trip.samp.log.tex}\nullskip
\end{stlog}

As only \input{sample.size.tex}\nullskip surveys were collected from a total of
\input{pop.size.tex}\nullskip riders, we would reasonably expect
that things do not align quite well. We expect weighting to correct for at least a portion of
that nonresponse. The data available for calibration includes the population turnstile counts
listed above, and we will produce interactions of daypart and station that will serve as two
weighting margins (one for the stations where the metro users boarded, and one for the stations
where they got off).

First, we need to define the weighting rules. In this case, the stations are numbered sequentially,
with the northernmost, say, station Alewife being number 3, and the southernmost station,
Union Station, where everybody gets off to rush to their city jobs or attractions, being number 73.
Below, we create a list of stations and provide it to \stcmd{wgtcellcollapse sequence}.
We would be collapsing stations along the line, with the expectation that travelers boarding or leaving
at adjacent stations within the same day part are more similar to one another than the travelers
boarding or leaving a particular station at different times of the day. Still, some collapsing rules
can be defined for the \stcmd{daypart} variable as well --- mostly because \stcmd{wgtcellcollapse collapse}
expects all variables to have collapsing rules defined.

\begin{stlog}
\input{ipfr.trip.rule.log.tex}\nullskip
\end{stlog}

The number of collapsing rules for variables \stcmd{board\_id} and \stcmd{alight\_id}
is \input{station.nrules.tex}\nullskip each.

\subsubsection{The first pass of weight collapse and raking}

Let us say that we want to define weighting cells with at least 20 cases in each.
We will thus start with weighting cells defined as station-by-daypart interaction,
and collapsing stations within daypart to achieve the cell sizes of at least 20 cases.
Here is what a simple run of \stcmd{wgtcellcollapse collapse} might look like.

\begin{stlog}
\input{ipfr.trip.att1.log.tex}\nullskip
\end{stlog}

The collapsed values of the variables \stcmd{dpston} (DayPart-STation-ON) and
\stcmd{dpstoff} (DayPart-STation-OFF) combine the values of the parent variables. The value
of \stcmd{dpston==1000003} indicates \stcmd{daypart==1} and station ID 3.
The value of \stcmd{dpston==2065270} indicates \stcmd{daypart==2} and sequence of
six stations from 52 to 70.
\label{page:dpston:nomenclature}

Note that \stcmd{wgtcellcollapse} returns a list of the cells that it could not
collapse in \stcmd{r(failed)} macro (and a comma delimited list, in \stcmd{f(cfailed)}).
These returned values should be used in production code by making an \stcmd{assert}
\citep{gould:2003:tip3} that these macros are empty.
While we know that some cell counts are less than 20, we will ignore the issue
for the moment, as there are bigger concerns with the collapsed cells at the moment,
as will become clear once we follow through with the workflow and attempt raking.

From the above run, \stcmd{wgtcellcollapse} produced two files, one for each
weighting margin, called \stcmd{dpston.do} and \stcmd{dpstoff.do}. An interested reader
is welcome to \stcmd{list} them; they contain long sequences of \stcmd{replace}
commands to perform the cell collapsing. The point of creating these is that they
can be run on the population data to create identical categories:

\begin{stlog}
\input{ipfr.trip.pop1.log.tex}\nullskip
\end{stlog}

Once that is done, we can go back to the sample data and try to create raking weights:

\begin{stlog}
\input{ipfr.trip.rake1.log.tex}\nullskip
\end{stlog}

We see that raking failed, because survey nonresponse wiped out some of the smaller
stations from the sample. (Note also the informative error message with
diagnostics of missing categories produced by \stcmd{ipfraking}. This is a functionality
added since the first 2010 publication in \textit{The Stata Journal}. The message lists
the categories found in the data, in the control totals, and in the mismatch.)

\subsubsection{The second pass of weight collapse and raking: \stcmd{zeroes()} option}

Having identified the issue, we can overcome it with \stcmd{zeroes()} option
of \stcmd{wgtcellcollapse collapse} which was developed specifically to address this issue.
This option provides the list of stations that may have zero sample counts
in a given daypart.
For instance, notice that the sample registers only one alighting at Brookline \stcmd{station==6})
in AM Peak daypart, even though there are passengers exiting in other dayparts. All in all,
\stcmd{wgtcellcollapse} needs to be made aware of the zero sample boardings at
Johnsville (39), King Street (40), Limerick (44), Ninth Street (49),
Queens Zoo (55) and Redline Circle (60); as well as zero alightings at Brookline (2),
Carmenton (8), Irvingtown (36),
Johnsville (39), King Street (40), Limerick (44), Moscow City (47), Ninth Street (49),
Ontario Lake (50), Queens Zoo (55), Redline Circle (60), and Silver Spring (62).

\begin{stlog}
\input{ipfr.trip.att2.log.tex}\nullskip
\end{stlog}

We will continue to disregard the cell counts of insufficient size for the time being.
Running the resulting do-files \stcmd{dpston.do} and \stcmd{dpstoff.do}
on the population data to create control totals, and providing these control totals
to \stcmd{ipfraking} program produces an apparently successful raking result:

\begin{stlog}
\input{ipfr.trip.rake2.log.tex}\nullskip
\end{stlog}

Note the use of utility program \stcmd{whatsdeff} to compute the design effect
due to unequal weighting; see section \ref{subsec:utility}. The problem of zero cells
appeared to have been solved: each and every population combination of daypart and station
is properly reflected in control total categories, and there are

The weighting cells, however, are still not without problems. Consider this
cross-tab of original and collapsed stations (the first part of the \ifexp expression identifies
the daypart, AM Peak; the second part identifies collapsed stations, given the nomenclature
of \stcmd{dpstoff} variable described on page \ref{page:dpston:nomenclature} as the concatenation
of the first variable of the interaction, \stcmd{daypart}; the length of the collapsed sequence,
and its starting and end points).

\begin{stlog}
\input{ipfr.trip.overlap2.log.tex}\nullskip
\end{stlog}

To the human eye, it is obvious that Picadilly Square (53) and Queens Zoo (55) should have been
a part of the six-station sequence 1064962 spanning from Ninth Street (49) to Silver Spring (62).
Instead, \stcmd{wgtcellcollapse} decided to separate these two stations out into their own cell.
How did that happen? The logic of \stcmd{wgtcellcollapse} is to collapse categories in such a way
as to produce the result with the smallest possible count. Thus, within AM Peak daypart,
the sequence of collapsing steps was as follows.

\begin{describe}
    \item[Pass 0] The zero cells were collapsed first: Johnsville (39) and King Street (40) resulting
        in an intermediate cell of size 3.
    \item[Pass 24] The smallest cell of size 1 (Brookline (2)) was collapsed with its neighbor
        (Carmenton (8)) resulting in an intermediate cell of size 12.
    \item[Pass 38] The smallest cell of size 2 (Ontario Lake (50)) was collapsed with its neighbor
        (Ninth Street (49)) resulting in an intermediate cell of size 5.
    \item[Pass 47] The smallest cell of size 3, collapsed Johnsville (39) and King Street (40),
        was further collapsed with its neighbor Irvingtown (36) resulting in an intermediate cell of size .
    \item[Pass 55] The smallest cell of size 5, Redline Circle (60), was collapsed by a three-way rule 
        with a duo Picadilly Square (53) + Queens Zoo (55), which actually was empty, and a small cell 
        Ontario Lake (50) + Ninth Street (49), resulting in an intermediate cell of size 10.
\end{describe}

Let us look at that last step in more detail. At this stage, Redline Circle (60) with 5 exiting passengers in
the sample could be collapsed with:
\begin{enumerate}
    \item Silver Spring (62), to form a cell of size 54;
    \item Queens Zoo (55), to form a cell of size 11;
    \item a sequence of Picadilly Square (53) and Queens Zoo (55), to form a cell of size 34;
    \item \ldots and many other options
\end{enumerate}
However, at pass 55, \stcmd{wgtcellcollapse} picked the rule 24950:25355:60=54960 which, at the time it was
processed, had a count of 5 in the cell 24950, a count of zero in the cell 25355, and a count of 5 in the
original station Redline Circle (60). (Note that the cell 25355 would actually form eventually at pass 58.)
The problem lies with the zero count of the ghost of the cell 25355.

To overcome this problem, \stcmd{wgtcellcollapse} have a \stcmd{strict} option that only allows the rules
that have a non-zero count in every component of the rule (so 24950:25355:60=54960 would not be a legal
merge under that option). As is easily seen, this option directly contradicts the \stcmd{zeroes()} option,
and that necessitates separate runs.

\subsubsection{The third pass of weight collapse and raking: \stcmd{strict} and \stcmd{feed} options}

We will separate the two runs of \stcmd{wgtcellcollapse} into a run that only deals with zeroes,
and another run that deals with everything else. To prevent \stcmd{wgtcellcollapse} from any further
merges, \stcmd{mincellsize(1)} can be specified in the first run. As the relevant variables will have already been
created by the first run, the option to pass the variable name to be further modified is
\stcmd{feed()}. To make sure that the relevant variable exists in the data set,
the option \stcmd{run} instructs \stcmd{wgtcellcollapse} to run the do-file it just created,
thus creating or modifying the collapsed cell variable.
Finally, instead of specifying \stcmd{replace} to overwrite the do-files that 
\stcmd{wgtcellcollapse} creates, we need to specify \stcmd{append} to keep adding to these files.

\begin{stlog}
\input{ipfr.trip.att3.log.tex}\nullskip
\end{stlog}

The result still isn't satisfactory, as some collapsed rules still overlap:

\begin{stlog}
\input{ipfr.trip.overlap3.log.tex}\nullskip
\end{stlog}

This overlap can be traced back to the collapsing of zero cells:
first, the cell 2023036 came to being by a reasonable, at its face, collapsing 
of the zero cell Irvingtown (36) with non-zero cell High Point (30);
and then the cell 2042639 came to being by a long overreach for the zero cell
Johnsville (39) to be collapsed with a non-zero cell Grand Junction (26).

\subsubsection{The fourth pass of weight collapse and raking: \stcmd{greedy} and \stcmd{maxcat()} options}

The process can be improved with an additional option \stcmd{greedy} that is applicable mostly
to the collapsing of zero cells. It modifies behavior of \stcmd{wgtcellcollapse} to require that,
among the possible candidate rules with the lowest count, the rule with the \textit{greatest} number 
of components is preferred. That is, the long streaks of zeroes from Irvingtown (36) to Limerick (44) in
midday part would be collapsed simultaneously. To support this option, and avoid complex collapses
of zero cells with the already defined cells, option \stcmd{maxcategory()} specifies the greatest
value of a component of a rule. By specifying \stcmd{maxcategory(99)}, we can instruct \stcmd{wgtcellcollapse}
to only use rules that deal with individual stations, and do not use the rules that involve collapsed
cells (which would have numbers of at least 20102 for the collapsed cell Alewife (1) and Brookline (2)).
In the first run, those collapsed cells will always be empty ghosts, and they should not be used.

Note also that with the \stcmd{greedy} option, one would want to specify the zeroes somewhere in the middle
of the streak, and possibly across multiple categories of the interacting variable. In our example,
specifying \stcmd(zeroes(36)} would collapse the midday streak of zero counts, but the need to collapse
the zeroes in the night and the weekend dayparts would still remain, necessitating something like
\stcmd{zeroes(40)} --- which, in turn, will likely create overlapping artifacts in the midday section.
However, specifying \stcmd{zeroes(40)} without \stcmd(zeroes(36)} would take care of all the streaks
observed in Table \ref{tab:sample:xtab}.

\begin{stlog}
\input{ipfr.trip.att4.log.tex}\nullskip
\end{stlog}

We have finally been able to produce a clean collapse of everything! Note the use of 
\stcmd{assert "`r(failed)'"==""} in the above code snippet to make sure that all cells have 
the minimal required size of 20.

As a very minor point, we can see some room for improvement in collapsing the cells on the weekend:

\begin{stlog}
\input{ipfr.trip.improve4.log.tex}\nullskip
\end{stlog}

Instead of two cells with sizes 141 and 32, it seems like we could produce three cells, with
Union Station (69) being its own cell, and everything else split somewhere in the middle.

\subsubsection{The fifth pass of weight collapse and raking: \ifexp\ conditions}

We will now code the collapsing cells for that day part ``by hand'', and we will put those
custom coded cells upfront before the main run.

\begin{stlog}
\input{ipfr.trip.att5.log.tex}\nullskip
\end{stlog}

This can now be applied to producing control totals, and running raking:

\begin{stlog}
\input{ipfr.trip.rake5.log.tex}\nullskip
\end{stlog}

\subsection{Linear calibrated weights}
\label{subsec:linear}

Using the existing example, let me demonstrate the linear calibration option of 
\stcmd{ipfraking}.

\begin{stlog}
\input{ipfr.trip.lin5.log.tex}\nullskip
\end{stlog}

\begin{figure}[h!]
    \begin{center}
    \epsfig{file=raked_linear}
    \end{center}
    \caption{Linear and raked weights}
    \label{fig:linear:raked}
\end{figure}















\subsection{Utility programs}
\label{subsec:utility}

The original package \stcmd{ipfraking} provided two additional utility programs,
\stcmd{mat2do} and \stcmd{xls2row}. An additional utility program was added
to compute the design effects and margins of error, common tasks associated
with describing survey weights. Specifically, the Transparency Initiative
of the American Association for Public Opinion Research
\citep{aapor:2014:ti:terms}
requires that

\begin{quote}
For probability samples, the estimates of sampling error will be reported, and the discussion will state whether or not the reported margins of sampling error or statistical analyses have been adjusted for the design effect due to weighting, clustering, or other factors.
\end{quote}

\begin{stsyntax}
whatsdeff
{\it weight\_variable}
\optif\
\optin\
,
\optional{
by(\varlist)
}
\end{stsyntax}

The utility program \stcmd{whatsdeff} calculates the apparent design effect due to unequal weighting,
${\rm DEFF_{UWE}}=1 + {CV}^2_w = $ \stcmd{1 + r(Var)/(r(mean))\^2} from \stcmd{summarize} {\it weight\_variable}.
Additionally, it reports the effective sample size, $n/{\rm DEFF_{UWE}}$, and also returns
the margins of error for the sample proportions that estimate the population proportions of
10\% and 50\%.

\begin{stlog}
\input{ipfr.whatsdeff.log.tex}\nullskip
\end{stlog}

















\clearpage\newpage






















\section{Examples}
\label{sec:examples}

\subsection{Basic syntax and input requirements}
\label{subsec:basic}

In this very simple example, I shall demonstrate the basic mechanics of
\stcmd{ipfraking}, its input requirements and output.
These examples are intended to only demonstrate the syntax
and the output of \stcmd{ipfraking}, and may or may not provide
substantively meaningful results.


\begin{stexample}[Example 1]

We shall work with the standard example of \stcmd{svy} data,
an excerpt from the NHANES II data set available from Stata Corp.\ website.
We shall introduce some small changes to the data so that
\stcmd{ipfraking} will have some work to do.

\begin{stlog}
\input{ipfr.example1.prep.log.tex}\nullskip
\end{stlog}

Let us now look at the matrices that will serve as an input to the
raking procedure.

\begin{stlog}
\input{ipfr.example1.list.log.tex}\nullskip
\end{stlog}

These input matrices are organized as follows. Input matrices always
have a single row, just as estimation results \stcmd{e(b)} do. The column
names follow the naming conventions of \stcmd{e(b)}, namely,
the name of the variable for which the total is being computed
(here, \stcmd{\_one}) and the numeric categories of the variable that
was used in the \stcmd{over} option (here, \stcmd{sex}, with values 1 for males
and 2 for females; and \stcmd{race}, with values 1 for whites, 2 for blacks,
and 3 for other). These values must be in an increasing order.
Since that variable is not stored in the e(b) per se,
it needs to be added to this matrix, which is done in the form of the row name.
The entries of the matrix are the totals that the weights in the categories
of the control variables need to sum up to. In this example, they are scaled
to be the population totals. Alternatively, these can be made to sum up to the
sample size, as is done sometimes in public opinion research, or to 1, which
is what \stcmd{proportion} estimation command would produce.

The input requirements in terms of control totals are thus made as simple as possible.
If a higher quality survey is available, all the survey statistician needs to do
is to obtain the totals for the categories of the control variables
using \stcmd{svy: total $\cdots$, over( $\cdots$, nolabel ) }
and save the name of that variable along with the matrix.
Note that the \stcmd{total}
is computed with \stcmd{over( \ldots, nolabel)} suboption to suppress
the otherwise informative labeling of the categories;
\stcmd{ipfraking} expects the numeric values of the categories
as column names (see \pref{matrix rownames}).
The name of the matrix itself is immaterial, but it is
a good programming practice
to have informative names \citep{mcconnell:2004}. Thus the names
of the matrices in the examples generally follow the convention
{\it data{\_}source}{\_}{\it variable}.

We are now ready to run \stcmd{ipfraking} and see what it produces.

\begin{stlog}
\input{ipfr.example1.run.log.tex}\nullskip
\end{stlog}

In this simple case with just two control variables
and the control totals that are not very different from the
existing sample totals, the procedure converged very quickly
in three iterations. A diagnostic message was produced upfront
by \stcmd{ipfraking} informing about apparent differences in
total population counts as obtained from the different
control total matrices. As a result, the control totals
for the variable that was adjusted first (\stcmd{sex})
could not match the required control totals even after the
weights converged in the sense of differing little between
iterations. Both of these warnings are only produced when
problems are encountered.

The summary table is always produced, and shows some relevant
characteristics of the original weights $w_{1j}$, the raked weights
$w_{3j}$, and the raking ratios $w_{3j}/w_{1j}$. As expected,
the coefficient of variation went up from 0.645 to 0.672.

The graphic output produced by \stcmd{ipfraking} is shown on
Figure \ref{fig:example1}. Generally, we would want to inspect these
graphs to see if there any unexpected patterns, such as highly outlying values,
gaps in the distribution (here, there are only six distinct values of the
adjustment factor corresponding to the $2\times3$ combinations of the control
variables) or concentration near the limits of the
weight range (as is typical for trimmed weights, see below in section
\ref{subsec:example:trimming}). Also, these graphs
may inform later trimming decisions: the trimming limits can be
chosen to conform to the breaks in the distributions of
the untrimmed raked weights.

\begin{figure}[h!]
\begin{center}
\epsfig{file=ipfraking_example1}
\end{center}
\caption{Histograms of the raked weights and calibration ratios, Example 1.}
\label{fig:example1}
\end{figure}

\end{stexample}

\subsection{Preparing control matrices from scratch}
\label{subsec:acs}

In many situations, the control totals will be obtained
from outside of Stata, and need to be prepared to work
with \stcmd{ipfraking}.

\begin{stexample}[Example 2]

Suppose I wanted to calibrate
the NHANES II data set to the latest control totals available
from the US Census Bureau website. Using the tables
S0101 from the 2011 American Community Survey 1-year estimates
and NST-EST2011 from the US Census Bureau population projections,
the latest available at the time of writing this paper,
the figures displayed in Table \ref{tab:example2} can be obtained.

\begin{table}
\caption{Control totals for the 2011 US population.\label{tab:example2}}

\centering

\begin{tabular}{p{5cm}l}
    Group & Population \\
    \hline
    \multicolumn{2}{c}{~~ACS 2011 1-year estimates, Table S0101~~} \\
    Male, total & 153,267,860 \\
    Ages 20--39 & 27.4\% \\
    Ages 40--59 & 27.5\% \\
    Ages 60+    & 17.3\% \\
    Female, total & 158,324,057 \\
    Ages 20--39 & 26.0\% \\
    Ages 40--59 & 27.6\% \\
    Ages 60+    & 20.7\% \\
    \multicolumn{2}{c}{~~US Census Bureau 2011 projections, Table NST-EST2011-01~~} \\
    Northeast & 55,521,598 \\
    Midwest   & 67,158,835 \\
    South     & 116,046,736 \\
    West      & 72,864,748 \\
    \multicolumn{2}{c}{~~US Census Bureau 2011 projections, Table NC-EST2011-03~~} \\
    White     & 243,470,497 \\
    Black     & 40,750,746 \\
    Other     & 27,370,674 \\
    \hline
    Total     & 311,591,917
\end{tabular}
\end{table}

Thus, we have information in the two-way age by sex table, as well
as two additional margins. We shall need an additional sex-by-age group variable,
and we shall try to make its values somewhat informative
(e.g., the value \stcmd{12} of the variable \stcmd{sex\_age} means
the first group of sex and the second group of age):

\begin{stlog}
\input{ipfr.example2.prep.log.tex}\nullskip
\end{stlog}

With that, the matrices will have to be defined explicitly,
and their labels need to be hand-coded, too (see \pref{matrix rownames}).
Note that the US Census Bureau 2011
projections relate to the total population, while the target population
of the study is the population age 20+. Assuming that the age structure
is the same across regions and races, the control totals for region and race
need to be rescaled to the adult population to avoid the warning messages.
(More accurate figures can be obtained from ACS microdata which can be downloaded
from the U.S.\ Census Bureau website.)

\begin{stlog}
\input{ipfr.example2.mat.log.tex}\nullskip
\end{stlog}

Let us check the matrix entries and labels once again before
producing the weights.
Note that the values of the control variable categories are given in an increasing order.

\begin{stlog}
\input{ipfr.example2.list.log.tex}\nullskip
\end{stlog}

As the labels appear to be in place, let us run \stcmd{ipfraking}:

\begin{stlog}
\input{ipfr.example2.run.log.tex}\nullskip
\end{stlog}

The diagnostic plots for these weights are given in Figure \ref{fig:example2}.
They do appear to have some outlying cases (which are not very clearly seen
on these plots as they are single count observations with outlying weights),
and we shall address them in the next section with trimming.

\begin{figure}[h!]
\begin{center}
\epsfig{file=ipfraking_example2}
\end{center}
\caption{Histograms of the raked weights and calibration ratios, Example 2.}
\label{fig:example2}
\end{figure}

\end{stexample}

\subsection{Trimming options}
\label{subsec:example:trimming}


As discussed in Section \ref{subsec:trimming} above, if variability of the weights
becomes excessive, the weights can be trimmed by restricting the extremes.
Using \stcmd{ipfraking} options, upper and/or lower limits can be defined
for either the absolute values of the weights or the relative changes from
the base weights. The frequency of the trimming operations can also be controlled.
Trimming can be applied once to the final data (\stcmd{trimfreq(once)})
at step \ref{step:trimfreq:once} of Algorithm 2.
Alternatively, trimming can be applied after every full cycle over variables
at step \ref{step:trimfreq:sometimes} of Algorithm 2.
Finally, trimming can be applied after each sub-iteration
at step \ref{step:trimfreq:often} of the algorithm.

\begin{stexample}[Example 3]

Inspecting the histograms on Figure \ref{fig:example2}, it appears reasonable
to restrict the upper tail of the raked weights. A more detailed investigation
of the histogram reveals a somewhat greater concentration of the raked weights
around the value of 160,000, and sparse bars beyond 200,000. This latter number
will be used as the top cut-off point for trimming, and is provided as an input
to \stcmd{ipfraking} via option \stcmd{trimhiabs}. Also, I specified the absolute
lower bound of 2,000, which is the minimum of the original weights, but,
as the output in the previous example suggested, the calibrated weights tend to run
above 4,000, so specifying the lower limit as \stcmd{trimloabs(2000)} may not really
affect the calibration procedure.

\begin{stlog}
\input{ipfr.example3.trimabs.log.tex}\nullskip
\end{stlog}

The resulting coefficient of variation of weights, 0.857, is slightly
better than that with unrestricted range of weights, 0.872. The summary also shows
that the weights were capped at 200,000, as requested.

Setting the absolute limits on the range of the raked weights is often
very subjective. A somewhat better plan might be to set limits in terms
of the range of the adjustment factors, as shown in the next example. The relative
change in the weights can be bounded with \stcmd{trimlorel()} and \stcmd{trimhirel()}
options.
I also demonstrate here how to use the results of \stcmd{summarize} to feed
into \stcmd{ipfraking}. While ensuring that accurate numbers are being carried
over in the context of the code, the approach is fragile for interactive
work: simply running the single line with the sole
\stcmd{ipfraking} command that refers to the \stcmd{r()} return values
may break down if \stcmd{summarize} was not the
immediately preceding command.

\begin{stlog}
\input{ipfr.example3.trimsum.log.tex}\nullskip
\end{stlog}

\end{stexample}

Setting the trimming options too aggressively may lead to adverse
consequences. First, it may bias the estimates, as discussed in Section
\ref{subsec:pro:con}.
Second, as this example demonstrates, it can impede (statistical) convergence:
the output contains multiple warnings about targets not being achieved
within desired accuracy, while no problems were encountered without trimming.

\subsection{Tracking convergence}
\label{subsec:example:trace}

Let us now look in more detail into the issue of trimming frequency,
and demonstrate another diagnostic plot that can be produced by
\stcmd{ipfraking}.

\begin{stexample}[Example 4]

We return to the first set of options of Example 3, and
re-run the raking procedure.

\begin{stlog}
\input{ipfr.example4.sometimes.log.tex}\nullskip
\end{stlog}

The option \stcmd{trace} requests that trace plots be added to
the diagnostic plots, as shown on Figure \ref{fig:example4:sometimes}.
The trace plots are presented on the absolute scale and on the log scale.
The exponentially declining discrepancy appears to be a general phenomenon.
In other words, after the first few iterations,
discrepancy between the currently weighted totals to the control totals roughly follows
the rate of $\rm{const} \times \alpha^k$ for some $\alpha<1$, where $k$ is
the (outer cycle) iteration number. When convergence is very slow or the sample
size is very large, this rule may be helpful in determining the number
of iterations necessary to achieve the required accuracy, and hence
the expected computing time. Zero cross-cells and collinearity between
the control variables may make the convergence factor $\alpha$ close to 1 thus
hampering convergence. This happens when the control variables have
very similar meaning, such as age and grade of children: it is impossible
to have children of age 8 in grade 10.
Also, sets of interactions of categorical variables, such as interactions
of age group and education along with age group and race, are guaranteed to
produce zero cells in the cross-tabulation: it is impossible to have
any observations in the cells defined say by
(age under 40 interacted with higher education) on one margin against
(age above 60 interacted with white race) on the other.

\begin{figure}[!th]
\begin{center}
\epsfig{file=ipfraking_example4_sometimes}
\end{center}
\caption{Diagnostic plots for Example 4.}
\label{fig:example4:sometimes}
\end{figure}

While \stcmd{trimfreq(sometimes)} is the default in presence
of other trimming options, the behavior can be changed
with explicit specification of trimming frequency. Note that slightly
different weights will be produced that way.

\begin{stlog}
\input{ipfr.example4.often.log.tex}\nullskip
\end{stlog}

In this example, trimming the weights after adjusting each of the margins
led to fewer iterations. This may or may not translate to lower overall
computing times as more computing is performed within each iteration.

\end{stexample}

\subsection{Metadata}
\label{subsec:example:meta}

The results of raking operations can be stored with the newly created
weight variables for later review and reproduction of the results.
Let us reproduce the example in the previous section adding all the metadata
available:

\begin{stexample}[Example 5]

\begin{stlog}
\input{ipfr.example5.log.tex}\nullskip
\end{stlog}

\end{stexample}

The following characteristics are stored with the newly created weight variable
(see \pref{char}).

\begin{tabular}{ll}
    \stcmd{command} & The full command as typed by the user \\
    {\it matrix name} & The relative matrix difference from the corresponding \\
                    & control total, see \dref{functions} \\
    \stcmd{trimhiabs}, \stcmd{trimloabs}, & Corresponding trimming options,
                    if specified \\
    \stcmd{trimhirel}, \stcmd{trimlorel}, & \\
    \stcmd{trimfrequency} & \\
    \stcmd{maxctrl} & the greatest \stcmd{mreldif} between the targets \\
                    & and the achieved weighted totals \\
    \stcmd{objfcn}  & the value of the relative weight change $D_k$ (\ref{eq:conv:ratio:weights})
                    at exit \\
    \stcmd{converged} & whether \stcmd{ipfraking} exited due to convergence (1) \\
                    & vs. due to an increase in the objective function \\
                    & or reaching the limit on the number of iterations (0)
\end{tabular}

Also, \stcmd{ipfraking} stores the notes regarding the control matrices
used, and which of the margins did not match the control totals, if any.
See \dref{notes}.

\subsection{Replicate weights}

As discussed in Section \ref{subsec:variance}, one of the greater challenges
of weight calibration is ensuring that variance estimates take into account
the greater precision achieved by adjusting the sample towards the fixed
population quantities. As estimating the variances using linearization
is cumbersome, replicate variance estimation may be more attractive.

\begin{stexample}[Example 6]

The simplest code for calibrated replicate weights is obtained by calling
\stcmd{ipfraking} from within \stcmd{bsweights} \citep{kolenikov:2010}
which can pass the name of a replicate weight variable to an arbitrary
calibration routine. In this example, we shall use the same settings
as in Section \ref{subsec:acs} and thus we shall have the calibrated weight
\stcmd{rakedwgt2} which was produced in that example as the main weight
for which the bootstrap weights provide the measure of sampling variability.

\begin{stlog}
\input{ipfr.example6.bsw.log.tex}\nullskip
\end{stlog}

The options of \stcmd{bsweights} request 310 replicate weights
(a multiple of 31 strata), resample one less PSU than available in
a given stratum, and obtain the first-order balance within a stratum.
With the 2 PSU/stratum design and these options, \stcmd{bsweights}
produces random half-samples of data. The at-character \stcmd{@} is a placeholder
for the name of the replicate weight variable.
For explanations of these and other options of \stcmd{bsweights},
see \citet{kolenikov:2010}. The procedure took about 3 minutes
on a laptop computer, which can be considered moderately
computationally intensive beyond interactive.
A new option of \stcmd{ipfraking} in the above code is
\stcmd{nograph} that suppresses the histograms.
The additional asserts \citep{gould:2003:tip3} following the bootstrap
weight generation demonstrate how the minimal quality assurance
can be done on the bootstrap weights in the weight production workflow.


A more compact set of weights can be developed based on the existing
BRR weights and a slightly more explicit code cycling over the weight
variables:

\begin{stlog}
\input{ipfr.example6.brr.log.tex}\nullskip
\end{stlog}

The data can be analyzed with the standard \stcmd{svy} prefix,
and the standard errors will appropriately capture the efficiency
gains from weight calibration. No additional action is required
for the analyst or researcher.

\end{stexample}

{\bf CAUTION:} the input weights for the replicate weight calibration
must be the probability replicate weights. The existing NHANES II weights
have been adjusted for non-response and calibrated by the data provider,
and are used above for demonstration purposes only.

\section{Error messages and troubleshooting}
\label{subsec:tbshooting}

\subsection{Critical errors}

The following critical errors will stop execution of
\stcmd{ipfraking}.

\noindent
{\tt pweight is required}

\morehang
    The \stcmd{[pweight=\ldots]} component of \stcmd{ipfraking}
    syntax is required. Probability weights must be specified as
    inputs to \stcmd{ipfraking}.

\noindent
    {\tt ctotal() is required}

    \morehang
    The \stcmd{ctotal()} component of \stcmd{ipfraking}
    syntax is required. Names of the matrices containing the
    control totals must be specified.

    \noindent
    {\tt one and only one of generate() or replace must be specified}

    \morehang
    Either \stcmd{generate()} option with the name of the new variable
    must be supplied to \stcmd{ipfraking}, or \stcmd{replace} to replace
    the variable specified in \stcmd{[pw=\ldots]} statement.

    \noindent
    {\tt raking procedure appears diverging}

    \morehang
    The maximum relative difference of weights $D_k$ has increased from
    the previous
    iteration. This may or may not indicate a problem. Re-run \stcmd{ipfraking}
    with \stcmd{nodivergence} option to override the warning.

    \noindent
    {\tt cannot process matrix {\it matrix{\_}name}}

    \morehang
    For whatever reason, \stcmd{ipfraking} could not process this matrix.
    The matrix may not have been defined or the variables in this matrix
    cannot be found.

    \noindent
    {\tt variable {\it varname} corresponding to the control matrix
    {\it matrix{\_}name} \\ not found}

    \morehang
    The variables contained in row or column names of this matrix
    cannot be found.

    \noindent
    {\tt {\it varname1} and {\it varname2} variables are not compatible}

    \morehang
    When running \stcmd{total} {\it varname1}\stcmd{, over(}{\it varname2}\stcmd{)},
    an error was encountered. One of the variables may be a string variable
    or have missing values resulting in an empty estimation sample.

    \noindent
    {\tt categories of {\it varname} do not match in the control {\it matrix{\_}name} \\
    and in the data (nolab option)}

    \morehang
    There was a mismatch in the categories of {\it varname} found in the data
    and in the control matrix {\it matrix{\_}name}. This could happen for any of the
    following reasons: (i) there were more categories in one than in the other;
    (ii) the entries are in the wrong order in the control matrix; (iii) the labels
    in the control matrix do not correspond to the category values in the data set;
    (iv) the control matrix was obtained via \stcmd{total}
    {\it varname2}\stcmd{, over(}{\it varname}\stcmd{)}, but \stcmd{nolabel} suboption
    of \stcmd{over()} was omitted, and the labels of the control matrix may include
    some unexpected text. Tabulate {\it varname} without labels, and compare the results
    to the matrix listing of the {\it matrix{\_}name}.

    \noindent
    {\tt cannot compute controls for {\it matrix{\_}name} over
    {\it varname} with the current \\ weights}

    \morehang
    This is a generic error message that something bad happened while
    \stcmd{ipfraking} was computing the totals for the current set of weights.
    This error message should generally be very rare, but as computing
    the totals may be the slowest operation of the iterative optimization
    process, stopping \stcmd{ipfraking} with a {\it Ctrl+Break} combination or
    the {\it Break} GUI button may produce this error message.

    \noindent
    {\tt trimhiabs|trimloabs|trimhirel|trimlorel must be a positive number}

    \morehang
    One or more of the trimming options are given as a non-positive number
    or a non-number.

    \noindent
    {\tt trimhiabs must be greater than trimloabs}

    \noindent
    {\tt trimhirel must be greater than trimlorel}

    \morehang
    The trimming parameters are illogical (the lower bound is greater than the upper bound).
    Respecify the values of the trimming parameters.

\bigskip

\subsection{Other errors and warnings}

The following warning messages may be produced by
\stcmd{ipfraking}. The program will continue running, but you must
double-check the results for potential problems.

\noindent
    {\tt the totals of the control matrices are different}

    \morehang
    The sum of values of the control matrices are different.
    These sums will be listed for review. Convergence is still
    possible, but some of the control total checks are likely to fail.

    \noindent
    {\tt trimfrequency() option is specified without numeric settings; will be \\ ignored}

    \morehang
    The option \stcmd{trimfrequency()} was specified without any numeric trimming options.
    There is no way to interpret this, and \stcmd{ipfraking} will proceed without
    trimming.

    \noindent
    {\tt trimfrequency() option is specified incorrectly, assume default value \\ (sometimes)}

    \morehang
    Something other than \stcmd{often}, \stcmd{sometimes} or \stcmd{once} was supplied
    in \stcmd{trimfrequency}, and the default value is being used instead.

    \noindent
    {\tt raking procedure did not converge}

    \morehang
    The maximum number of iterations was reached, but weights never met the convergence
    criteria (see step \ref{step:check:weight:conv} of Algorithm 2 in Section \ref{subsec:trimming}).
    The user may want to increase the number of iterations or relax convergence criteria.

    \noindent
    {\tt the controls {\it matrix{\_}name} did not match}

    \morehang
    After convergence of weights was declared, \stcmd{ipfraking}
    checked again the control totals, and found that the results
    differed from the target for one or more of the control total
    matrices. Any of the following can cause this: (i) the sum of
    entries of this particular matrix differs from the others;
    (ii) the trimming options are too restrictive, and do not allow
    the weights to adjust enough; (iii) the problem may not have a
    solution due to incompatible control totals or a bad sample.

    \noindent
    {\tt division by zero weighted total encountered with
    {\it matrix{\_}name} control}

    \morehang
    The weights for a category of the control variable summed
    to zero. \stcmd{ipfraking} will skip calibration over this
    variable and proceed to the next one.

    \noindent
    {\tt \# missing values of {\it varname} encountered; convergence will be impaired}

    \morehang
    A control variable has missing values in the calibration sample.
    There is little way for \stcmd{ipfraking} to figure out how to deal
    with the weights for the observations with missing values. The user would need
    either to restrict the sample to non-missing values of all control variables,
    to impute the missing values or to create a separate category for the missing
    values of a given control variable (which may lead to difficulties in defining
    valid population control totals for it).

\section*{Acknowledgements}

The author is grateful to Ben Phillips, Andrew Burkey and Brady West,
as well as the editor and an anonymous referee,
who suggested additional functionality and provided helpful comments
to improve the readability of this article. The opinions stated in this paper
are of the author only, and do not represent the position of Abt Associates.

\bibliographystyle{sj}
\bibliography{everything}
% \bibliography{ipfraking}

\begin{aboutauthor}
  Stanislav (Stas) Kolenikov is a Senior Scientist at Abt Associates.
  His work involves applications of statistical methods in data collection
  for public opinion research, public health, transportation, and other disciplines
  that utilize collection of survey data.
  Within survey methodology, his expertise includes advanced sampling techniques,
  survey weighting, calibration, missing data imputation, variance estimation,
  nonresponse analysis and adjustment, and small area estimation.
  Besides survey statistics, Stas has extensive experience developing and applying
  statistical methods in social sciences, with focus on structural equation
  modeling and microeconometrics. He has been writing Stata programs since
  1998 when Stata was version 5.
\end{aboutauthor}
